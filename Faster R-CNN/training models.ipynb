{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "#from engine import train_one_epoch, evaluate\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import PIL.Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "from face_mask_datasets import MaskDetectionDatasetJSON, MaskDetectionDatasetXML\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "CLASS_LABELS_ALL = {\n",
    "    \"hijab_niqab\": 0,\n",
    "    \"mask_colorful\": 1,\n",
    "    \"mask_surgical\": 2,\n",
    "    \"face_no_mask\": 3,\n",
    "    \"face_with_mask_incorrect\": 4,\n",
    "    \"face_with_mask\": 5,\n",
    "    \"face_other_covering\": 6,\n",
    "    \"scarf_bandana\": 7,\n",
    "    \"balaclava_ski_mask\": 8,\n",
    "    \"face_shield\": 9,\n",
    "    \"other\": 10,\n",
    "    \"gas_mask\": 11,\n",
    "    \"turban\": 12,\n",
    "    \"helmet\": 13,\n",
    "    \"sunglasses\": 14,\n",
    "    \"eyeglasses\": 15,\n",
    "    \"hair_net\": 16,\n",
    "    \"hat\": 17,\n",
    "    \"goggles\": 18,\n",
    "    \"hood\": 19\n",
    "}\n",
    "\n",
    "CLASS_LABELS_FACES = {\n",
    "    \"face_no_mask\": 0,\n",
    "    \"face_with_mask_incorrect\": 1,\n",
    "    \"face_with_mask\": 2,\n",
    "    \"face_other_covering\": 3\n",
    "}\n",
    "\n",
    "TRAIN_PRECENTAGE = 0.8  # 80% of the data is used for training\n",
    "BATCH_SIZE = 12\n",
    "NUM_EPOCHS = 1\n",
    "LEARNING_RATE = 0.005\n",
    "print(\"Using device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_big = MaskDetectionDatasetJSON(\"C:\\GIT_Workspaces\\Deep-Vision-sta\\Datasets\\Face Mask Detection Dataset\\Medical mask\\Medical mask\\Medical Mask\",CLASS_LABELS, (512,512))\n",
    "# dataset_big_singleFaces = MaskDetectionDatasetJSON(\"C:\\GIT_Workspaces\\Deep-Vision-sta\\Datasets\\Face Mask Detection Dataset\\Medical mask\\Medical mask\\Medical Mask\",CLASS_LABELS,(512,512), only_single_faces=True)\n",
    "# dataset_big_multipleFaces = MaskDetectionDatasetJSON(\"C:\\GIT_Workspaces\\Deep-Vision-sta\\Datasets\\Face Mask Detection Dataset\\Medical mask\\Medical mask\\Medical Mask\",CLASS_LABELS,(512,512), only_multiple_faces=True)\n",
    "\n",
    "# dataset_small = MaskDetectionDatasetXML(\"C:\\GIT_Workspaces\\Deep-Vision-sta\\Datasets\\Kaggle Face Mask Detection Full\",(512,512))\n",
    "# dataset_small_low_light = MaskDetectionDatasetXML(\"C:\\GIT_Workspaces\\Deep-Vision-sta\\Datasets\\Kaggle Face Mask Detection Full\",(512,512), use_dark_images=True)\n",
    "\n",
    "# #create a dict of the datasets\n",
    "\n",
    "# datasets = {\n",
    "#     \"dataset_big\": dataset_big,\n",
    "#     \"dataset_big_singleFaces\": dataset_big_singleFaces,\n",
    "#     \"dataset_big_multipleFaces\": dataset_big_multipleFaces,\n",
    "#     \"dataset_small\": dataset_small,\n",
    "#     \"dataset_small_low_light\": dataset_small_low_light\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GIT_Workspaces\\Deep-Vision-sta\\Faster R-CNN\\face_mask_datasets.py:59: UserWarning: File 1855.jpg has no annotations\n",
      "  warnings.warn(f\"File {file_name} has no annotations\")\n",
      "c:\\GIT_Workspaces\\Deep-Vision-sta\\Faster R-CNN\\face_mask_datasets.py:59: UserWarning: File 1945.jpg has no annotations\n",
      "  warnings.warn(f\"File {file_name} has no annotations\")\n",
      "c:\\GIT_Workspaces\\Deep-Vision-sta\\Faster R-CNN\\face_mask_datasets.py:59: UserWarning: File 2135.jpg has no annotations\n",
      "  warnings.warn(f\"File {file_name} has no annotations\")\n",
      "c:\\GIT_Workspaces\\Deep-Vision-sta\\Faster R-CNN\\face_mask_datasets.py:59: UserWarning: File 3102.png has no annotations\n",
      "  warnings.warn(f\"File {file_name} has no annotations\")\n",
      "c:\\GIT_Workspaces\\Deep-Vision-sta\\Faster R-CNN\\face_mask_datasets.py:59: UserWarning: File 4618.png has no annotations\n",
      "  warnings.warn(f\"File {file_name} has no annotations\")\n",
      "c:\\GIT_Workspaces\\Deep-Vision-sta\\Faster R-CNN\\face_mask_datasets.py:59: UserWarning: File 5012.jpg has no annotations\n",
      "  warnings.warn(f\"File {file_name} has no annotations\")\n",
      "c:\\GIT_Workspaces\\Deep-Vision-sta\\Faster R-CNN\\face_mask_datasets.py:59: UserWarning: File 5023.jpg has no annotations\n",
      "  warnings.warn(f\"File {file_name} has no annotations\")\n",
      "c:\\GIT_Workspaces\\Deep-Vision-sta\\Faster R-CNN\\face_mask_datasets.py:59: UserWarning: File 5052.jpg has no annotations\n",
      "  warnings.warn(f\"File {file_name} has no annotations\")\n",
      "c:\\GIT_Workspaces\\Deep-Vision-sta\\Faster R-CNN\\face_mask_datasets.py:59: UserWarning: File 5277.jpg has no annotations\n",
      "  warnings.warn(f\"File {file_name} has no annotations\")\n",
      "c:\\GIT_Workspaces\\Deep-Vision-sta\\Faster R-CNN\\face_mask_datasets.py:59: UserWarning: File 5418.jpg has no annotations\n",
      "  warnings.warn(f\"File {file_name} has no annotations\")\n",
      "c:\\GIT_Workspaces\\Deep-Vision-sta\\Faster R-CNN\\face_mask_datasets.py:59: UserWarning: File 5430.jpg has no annotations\n",
      "  warnings.warn(f\"File {file_name} has no annotations\")\n",
      "c:\\GIT_Workspaces\\Deep-Vision-sta\\Faster R-CNN\\face_mask_datasets.py:59: UserWarning: File 5443.jpg has no annotations\n",
      "  warnings.warn(f\"File {file_name} has no annotations\")\n"
     ]
    }
   ],
   "source": [
    "dataset_big_all_classes = MaskDetectionDatasetJSON(\"C:\\GIT_Workspaces\\Deep-Vision-sta\\Datasets\\Face Mask Detection Dataset\\Medical mask\\Medical mask\\Medical Mask\",CLASS_LABELS_ALL, (512,512), allowed_classes=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19])\n",
    "dataset_big_face_classes = MaskDetectionDatasetJSON(\"C:\\GIT_Workspaces\\Deep-Vision-sta\\Datasets\\Face Mask Detection Dataset\\Medical mask\\Medical mask\\Medical Mask\",CLASS_LABELS_FACES,(512,512), allowed_classes=[0,1,2,3])\n",
    "\n",
    "#create a dict of the datasets\n",
    "\n",
    "datasets = {\n",
    "    \"dataset_big_all_classes\": dataset_big_all_classes,\n",
    "    \"dataset_big_face_classes\": dataset_big_face_classes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'isProtected': False,\n",
       "   'ID': 537667945160657984,\n",
       "   'BoundingBox': [680, 340, 1664, 1784],\n",
       "   'classname': 'face_no_mask',\n",
       "   'Confidence': 1,\n",
       "   'Attributes': {}}],\n",
       " '1856.jpg')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_big_face_classes.annotations[52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'isProtected': False,\n",
       "   'ID': 702780802691515392,\n",
       "   'BoundingBox': [480, 143, 586, 230],\n",
       "   'classname': 'mask_surgical',\n",
       "   'Confidence': 1,\n",
       "   'Attributes': {}}],\n",
       " '1855.jpg')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_big_all_classes.annotations[52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4314"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_big_face_classes.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataloaders for datasets\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import utils\n",
    "\n",
    "dataloaders = {}\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    train_size = int(TRAIN_PRECENTAGE * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=utils.collate_fn)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=utils.collate_fn)\n",
    "    dataloaders[dataset_name] = {\n",
    "        \"train\": train_dataloader,\n",
    "        \"test\": test_dataloader\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johan\\.conda\\envs\\DV-STA\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\johan\\.conda\\envs\\DV-STA\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\johan\\.conda\\envs\\DV-STA\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_MobileNet_V3_Large_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_MobileNet_V3_Large_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_resnet_all_classes = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model_resnet_face_classes = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model_mobile_all_classes = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
    "model_mobile_face_classes = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
    "\n",
    "models_classComparison = {\n",
    "    \"resnet\":{\n",
    "        \"all_classes\": model_resnet_all_classes,\n",
    "        \"face_classes\": model_resnet_face_classes\n",
    "    },\n",
    "    \"mobile\":{\n",
    "        \"all_classes\": model_mobile_all_classes,\n",
    "        \"face_classes\": model_mobile_face_classes\n",
    "    }\n",
    "}\n",
    "\n",
    "num_classes = {\n",
    "    \"all_classes\": 20,\n",
    "    \"face_classes\": 4\n",
    "}\n",
    "\n",
    "#prepare models\n",
    "\n",
    "for model_name, model_dict in models_classComparison.items():\n",
    "    for model_type, model in model_dict.items():\n",
    "        # get number of input features for the classifier\n",
    "        in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "        # number of classes\n",
    "        nc = num_classes[model_type]\n",
    "\n",
    "        # replace the pre-trained head with a new one\n",
    "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, nc)\n",
    "\n",
    "        # move model to the right device\n",
    "        model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['face_with_mask_incorrect', 'face_with_mask', 'face_no_mask', 'face_other_covering']\n"
     ]
    }
   ],
   "source": [
    "classnames = set()\n",
    "\n",
    "for item in dataset_big_face_classes.annotations:\n",
    "    objects, _ = item\n",
    "    for obj in objects:\n",
    "        classnames.add(obj['classname'])\n",
    "\n",
    "unique_classnames = list(classnames)\n",
    "print(unique_classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "def train_model(model, dataloaders, optimizer, num_epochs=10):\n",
    "\n",
    "    # Define empty arrays to collect metrics\n",
    "    ap_values = []\n",
    "    ar_values = []\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        # train for one epoch, printing every 10 iterations\n",
    "        train_one_epoch(model, optimizer, dataloaders[\"train\"], device, epoch, print_freq=1, losses_out=losses)\n",
    "        # evaluate on the test dataset\n",
    "        evaluator = evaluate(model, dataloaders[\"test\"], device)\n",
    "\n",
    "        # Extract the metrics from the evaluator\n",
    "        average_precisions = evaluator.coco_eval['bbox'].stats[:6]\n",
    "        average_recalls = evaluator.coco_eval['bbox'].stats[6:]\n",
    "\n",
    "        # Append the metrics to the arrays\n",
    "        ap_values.append(average_precisions)\n",
    "        ar_values.append(average_recalls)\n",
    "\n",
    "    return model, ap_values, ar_values, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_model(model_resnet_all_classes, dataloaders[\"dataset_big_all_classes\"], SGD(model_resnet_all_classes.parameters(), lr=LEARNING_RATE), num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4326"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"dataset_big_all_classes\"].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4326"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_big_all_classes.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4314"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_big_face_classes.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4314"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"dataset_big_face_classes\"].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/288]  eta: 0:16:15  lr: 0.000022  loss: 1.7590 (1.7590)  loss_classifier: 1.5279 (1.5279)  loss_box_reg: 0.1420 (0.1420)  loss_objectness: 0.0427 (0.0427)  loss_rpn_box_reg: 0.0464 (0.0464)  time: 3.3860  data: 0.2070  max mem: 8869\n",
      "Epoch: [0]  [  1/288]  eta: 0:10:05  lr: 0.000040  loss: 1.7590 (1.7658)  loss_classifier: 1.5279 (1.5290)  loss_box_reg: 0.1420 (0.1619)  loss_objectness: 0.0427 (0.0468)  loss_rpn_box_reg: 0.0098 (0.0281)  time: 2.1110  data: 0.1600  max mem: 8870\n",
      "Epoch: [0]  [  2/288]  eta: 0:07:53  lr: 0.000057  loss: 1.7725 (1.7796)  loss_classifier: 1.5279 (1.5235)  loss_box_reg: 0.1818 (0.1761)  loss_objectness: 0.0509 (0.0548)  loss_rpn_box_reg: 0.0194 (0.0252)  time: 1.6540  data: 0.1453  max mem: 8870\n",
      "Epoch: [0]  [  3/288]  eta: 0:06:59  lr: 0.000075  loss: 1.7590 (1.7713)  loss_classifier: 1.5279 (1.5282)  loss_box_reg: 0.1609 (0.1723)  loss_objectness: 0.0427 (0.0491)  loss_rpn_box_reg: 0.0112 (0.0217)  time: 1.4720  data: 0.1645  max mem: 8870\n",
      "Epoch: [0]  [  4/288]  eta: 0:06:28  lr: 0.000092  loss: 1.7590 (1.7590)  loss_classifier: 1.5279 (1.5231)  loss_box_reg: 0.1611 (0.1701)  loss_objectness: 0.0427 (0.0467)  loss_rpn_box_reg: 0.0112 (0.0191)  time: 1.3678  data: 0.1778  max mem: 8870\n",
      "Epoch: [0]  [  5/288]  eta: 0:06:00  lr: 0.000109  loss: 1.7465 (1.7411)  loss_classifier: 1.5124 (1.5209)  loss_box_reg: 0.1609 (0.1581)  loss_objectness: 0.0374 (0.0450)  loss_rpn_box_reg: 0.0098 (0.0171)  time: 1.2753  data: 0.1697  max mem: 8870\n",
      "Epoch: [0]  [  6/288]  eta: 0:05:41  lr: 0.000127  loss: 1.7465 (1.7302)  loss_classifier: 1.5124 (1.5151)  loss_box_reg: 0.1609 (0.1506)  loss_objectness: 0.0427 (0.0486)  loss_rpn_box_reg: 0.0098 (0.0158)  time: 1.2124  data: 0.1614  max mem: 8870\n",
      "Epoch: [0]  [  7/288]  eta: 0:05:25  lr: 0.000144  loss: 1.7099 (1.7273)  loss_classifier: 1.5103 (1.5017)  loss_box_reg: 0.1609 (0.1586)  loss_objectness: 0.0427 (0.0517)  loss_rpn_box_reg: 0.0098 (0.0153)  time: 1.1599  data: 0.1561  max mem: 8870\n",
      "Epoch: [0]  [  8/288]  eta: 0:05:16  lr: 0.000162  loss: 1.7099 (1.7170)  loss_classifier: 1.5103 (1.4951)  loss_box_reg: 0.1609 (0.1534)  loss_objectness: 0.0509 (0.0533)  loss_rpn_box_reg: 0.0112 (0.0151)  time: 1.1294  data: 0.1599  max mem: 8870\n",
      "Epoch: [0]  [  9/288]  eta: 0:05:07  lr: 0.000179  loss: 1.7072 (1.7063)  loss_classifier: 1.5025 (1.4827)  loss_box_reg: 0.1609 (0.1545)  loss_objectness: 0.0509 (0.0544)  loss_rpn_box_reg: 0.0105 (0.0147)  time: 1.1019  data: 0.1595  max mem: 8870\n",
      "Epoch: [0]  [ 10/288]  eta: 0:04:59  lr: 0.000196  loss: 1.7072 (1.6960)  loss_classifier: 1.5025 (1.4717)  loss_box_reg: 0.1611 (0.1570)  loss_objectness: 0.0509 (0.0531)  loss_rpn_box_reg: 0.0105 (0.0142)  time: 1.0775  data: 0.1575  max mem: 8870\n",
      "Epoch: [0]  [ 11/288]  eta: 0:04:53  lr: 0.000214  loss: 1.6647 (1.6803)  loss_classifier: 1.4801 (1.4608)  loss_box_reg: 0.1609 (0.1543)  loss_objectness: 0.0427 (0.0515)  loss_rpn_box_reg: 0.0098 (0.0137)  time: 1.0579  data: 0.1562  max mem: 8870\n",
      "Epoch: [0]  [ 12/288]  eta: 0:04:47  lr: 0.000231  loss: 1.6647 (1.6583)  loss_classifier: 1.4801 (1.4427)  loss_box_reg: 0.1609 (0.1505)  loss_objectness: 0.0509 (0.0518)  loss_rpn_box_reg: 0.0098 (0.0134)  time: 1.0420  data: 0.1556  max mem: 8870\n",
      "Epoch: [0]  [ 13/288]  eta: 0:04:42  lr: 0.000249  loss: 1.6516 (1.6400)  loss_classifier: 1.4424 (1.4241)  loss_box_reg: 0.1609 (0.1526)  loss_objectness: 0.0427 (0.0504)  loss_rpn_box_reg: 0.0098 (0.0129)  time: 1.0259  data: 0.1536  max mem: 8870\n",
      "Epoch: [0]  [ 14/288]  eta: 0:04:35  lr: 0.000266  loss: 1.6516 (1.6224)  loss_classifier: 1.4424 (1.4063)  loss_box_reg: 0.1609 (0.1531)  loss_objectness: 0.0503 (0.0504)  loss_rpn_box_reg: 0.0098 (0.0126)  time: 1.0070  data: 0.1544  max mem: 8870\n",
      "Epoch: [0]  [ 15/288]  eta: 0:04:30  lr: 0.000283  loss: 1.6340 (1.6057)  loss_classifier: 1.4082 (1.3894)  loss_box_reg: 0.1609 (0.1554)  loss_objectness: 0.0427 (0.0485)  loss_rpn_box_reg: 0.0092 (0.0123)  time: 0.9910  data: 0.1546  max mem: 8870\n",
      "Epoch: [0]  [ 16/288]  eta: 0:04:24  lr: 0.000301  loss: 1.6340 (1.5889)  loss_classifier: 1.4082 (1.3743)  loss_box_reg: 0.1609 (0.1521)  loss_objectness: 0.0503 (0.0501)  loss_rpn_box_reg: 0.0098 (0.0124)  time: 0.9741  data: 0.1525  max mem: 8870\n",
      "Epoch: [0]  [ 17/288]  eta: 0:04:20  lr: 0.000318  loss: 1.6102 (1.5704)  loss_classifier: 1.3706 (1.3561)  loss_box_reg: 0.1600 (0.1490)  loss_objectness: 0.0503 (0.0528)  loss_rpn_box_reg: 0.0098 (0.0125)  time: 0.9601  data: 0.1512  max mem: 8870\n",
      "Epoch: [0]  [ 18/288]  eta: 0:04:15  lr: 0.000336  loss: 1.6102 (1.5532)  loss_classifier: 1.3706 (1.3379)  loss_box_reg: 0.1600 (0.1495)  loss_objectness: 0.0509 (0.0535)  loss_rpn_box_reg: 0.0098 (0.0124)  time: 0.9468  data: 0.1499  max mem: 8870\n",
      "Epoch: [0]  [ 19/288]  eta: 0:04:12  lr: 0.000353  loss: 1.5935 (1.5303)  loss_classifier: 1.3618 (1.3177)  loss_box_reg: 0.1591 (0.1473)  loss_objectness: 0.0503 (0.0533)  loss_rpn_box_reg: 0.0095 (0.0121)  time: 0.9386  data: 0.1519  max mem: 8870\n",
      "Epoch: [0]  [ 20/288]  eta: 0:04:08  lr: 0.000370  loss: 1.5076 (1.5066)  loss_classifier: 1.3412 (1.2973)  loss_box_reg: 0.1591 (0.1426)  loss_objectness: 0.0509 (0.0548)  loss_rpn_box_reg: 0.0092 (0.0119)  time: 0.8048  data: 0.1476  max mem: 8870\n",
      "Epoch: [0]  [ 21/288]  eta: 0:04:07  lr: 0.000388  loss: 1.4023 (1.4852)  loss_classifier: 1.2251 (1.2778)  loss_box_reg: 0.1248 (0.1418)  loss_objectness: 0.0503 (0.0539)  loss_rpn_box_reg: 0.0090 (0.0117)  time: 0.8098  data: 0.1598  max mem: 8870\n",
      "Epoch: [0]  [ 22/288]  eta: 0:04:04  lr: 0.000405  loss: 1.3937 (1.4615)  loss_classifier: 1.1828 (1.2572)  loss_box_reg: 0.1238 (0.1407)  loss_objectness: 0.0496 (0.0523)  loss_rpn_box_reg: 0.0089 (0.0114)  time: 0.8088  data: 0.1602  max mem: 8870\n",
      "Epoch: [0]  [ 23/288]  eta: 0:04:01  lr: 0.000423  loss: 1.3759 (1.4381)  loss_classifier: 1.1570 (1.2366)  loss_box_reg: 0.1164 (0.1388)  loss_objectness: 0.0496 (0.0516)  loss_rpn_box_reg: 0.0086 (0.0111)  time: 0.7984  data: 0.1550  max mem: 8870\n",
      "Epoch: [0]  [ 24/288]  eta: 0:03:58  lr: 0.000440  loss: 1.3548 (1.4178)  loss_classifier: 1.1352 (1.2167)  loss_box_reg: 0.1164 (0.1389)  loss_objectness: 0.0496 (0.0510)  loss_rpn_box_reg: 0.0086 (0.0112)  time: 0.7870  data: 0.1495  max mem: 8870\n",
      "Epoch: [0]  [ 25/288]  eta: 0:03:56  lr: 0.000458  loss: 1.3202 (1.3973)  loss_classifier: 1.1329 (1.1970)  loss_box_reg: 0.1238 (0.1391)  loss_objectness: 0.0496 (0.0502)  loss_rpn_box_reg: 0.0086 (0.0110)  time: 0.7860  data: 0.1535  max mem: 8870\n",
      "Epoch: [0]  [ 26/288]  eta: 0:03:54  lr: 0.000475  loss: 1.2561 (1.3807)  loss_classifier: 1.0461 (1.1775)  loss_box_reg: 0.1248 (0.1417)  loss_objectness: 0.0496 (0.0504)  loss_rpn_box_reg: 0.0090 (0.0110)  time: 0.7816  data: 0.1554  max mem: 8870\n",
      "Epoch: [0]  [ 27/288]  eta: 0:03:51  lr: 0.000492  loss: 1.2444 (1.3605)  loss_classifier: 1.0106 (1.1568)  loss_box_reg: 0.1248 (0.1435)  loss_objectness: 0.0409 (0.0493)  loss_rpn_box_reg: 0.0090 (0.0110)  time: 0.7799  data: 0.1568  max mem: 8870\n",
      "Epoch: [0]  [ 28/288]  eta: 0:03:49  lr: 0.000510  loss: 1.0943 (1.3378)  loss_classifier: 0.9336 (1.1354)  loss_box_reg: 0.1248 (0.1416)  loss_objectness: 0.0409 (0.0500)  loss_rpn_box_reg: 0.0086 (0.0109)  time: 0.7719  data: 0.1542  max mem: 8870\n",
      "Epoch: [0]  [ 29/288]  eta: 0:03:47  lr: 0.000527  loss: 1.0356 (1.3166)  loss_classifier: 0.8896 (1.1151)  loss_box_reg: 0.1238 (0.1410)  loss_objectness: 0.0375 (0.0496)  loss_rpn_box_reg: 0.0086 (0.0110)  time: 0.7664  data: 0.1543  max mem: 8870\n",
      "Epoch: [0]  [ 30/288]  eta: 0:03:45  lr: 0.000545  loss: 1.0328 (1.2936)  loss_classifier: 0.8698 (1.0950)  loss_box_reg: 0.1224 (0.1387)  loss_objectness: 0.0370 (0.0491)  loss_rpn_box_reg: 0.0081 (0.0108)  time: 0.7624  data: 0.1559  max mem: 8870\n",
      "Epoch: [0]  [ 31/288]  eta: 0:03:43  lr: 0.000562  loss: 0.9506 (1.2752)  loss_classifier: 0.8031 (1.0757)  loss_box_reg: 0.1224 (0.1384)  loss_objectness: 0.0375 (0.0502)  loss_rpn_box_reg: 0.0086 (0.0109)  time: 0.7558  data: 0.1547  max mem: 8870\n",
      "Epoch: [0]  [ 32/288]  eta: 0:03:41  lr: 0.000579  loss: 0.9411 (1.2541)  loss_classifier: 0.7637 (1.0566)  loss_box_reg: 0.1224 (0.1371)  loss_objectness: 0.0370 (0.0496)  loss_rpn_box_reg: 0.0086 (0.0109)  time: 0.7493  data: 0.1539  max mem: 8870\n",
      "Epoch: [0]  [ 33/288]  eta: 0:03:39  lr: 0.000597  loss: 0.9314 (1.2374)  loss_classifier: 0.7381 (1.0384)  loss_box_reg: 0.1224 (0.1379)  loss_objectness: 0.0375 (0.0504)  loss_rpn_box_reg: 0.0086 (0.0107)  time: 0.7432  data: 0.1529  max mem: 8870\n",
      "Epoch: [0]  [ 34/288]  eta: 0:03:37  lr: 0.000614  loss: 0.8986 (1.2174)  loss_classifier: 0.7033 (1.0197)  loss_box_reg: 0.1164 (0.1372)  loss_objectness: 0.0370 (0.0500)  loss_rpn_box_reg: 0.0081 (0.0106)  time: 0.7416  data: 0.1509  max mem: 8870\n",
      "Epoch: [0]  [ 35/288]  eta: 0:03:35  lr: 0.000632  loss: 0.8836 (1.2010)  loss_classifier: 0.6722 (1.0025)  loss_box_reg: 0.1164 (0.1373)  loss_objectness: 0.0375 (0.0506)  loss_rpn_box_reg: 0.0090 (0.0106)  time: 0.7398  data: 0.1494  max mem: 8870\n",
      "Epoch: [0]  [ 36/288]  eta: 0:03:33  lr: 0.000649  loss: 0.8160 (1.1844)  loss_classifier: 0.5962 (0.9854)  loss_box_reg: 0.1224 (0.1381)  loss_objectness: 0.0375 (0.0503)  loss_rpn_box_reg: 0.0081 (0.0105)  time: 0.7408  data: 0.1503  max mem: 8870\n",
      "Epoch: [0]  [ 37/288]  eta: 0:03:33  lr: 0.000666  loss: 0.7044 (1.1664)  loss_classifier: 0.5365 (0.9682)  loss_box_reg: 0.1224 (0.1375)  loss_objectness: 0.0375 (0.0504)  loss_rpn_box_reg: 0.0077 (0.0104)  time: 0.7527  data: 0.1627  max mem: 8870\n",
      "Epoch: [0]  [ 38/288]  eta: 0:03:32  lr: 0.000684  loss: 0.7020 (1.1501)  loss_classifier: 0.5278 (0.9521)  loss_box_reg: 0.1224 (0.1372)  loss_objectness: 0.0375 (0.0504)  loss_rpn_box_reg: 0.0077 (0.0103)  time: 0.7599  data: 0.1701  max mem: 8870\n",
      "Epoch: [0]  [ 39/288]  eta: 0:03:30  lr: 0.000701  loss: 0.7016 (1.1343)  loss_classifier: 0.4927 (0.9364)  loss_box_reg: 0.1238 (0.1373)  loss_objectness: 0.0375 (0.0503)  loss_rpn_box_reg: 0.0081 (0.0103)  time: 0.7559  data: 0.1658  max mem: 8870\n",
      "Epoch: [0]  [ 40/288]  eta: 0:03:29  lr: 0.000719  loss: 0.6856 (1.1174)  loss_classifier: 0.4760 (0.9205)  loss_box_reg: 0.1285 (0.1371)  loss_objectness: 0.0370 (0.0495)  loss_rpn_box_reg: 0.0077 (0.0102)  time: 0.7557  data: 0.1655  max mem: 8870\n",
      "Epoch: [0]  [ 41/288]  eta: 0:03:28  lr: 0.000736  loss: 0.6262 (1.1013)  loss_classifier: 0.4447 (0.9055)  loss_box_reg: 0.1285 (0.1360)  loss_objectness: 0.0375 (0.0497)  loss_rpn_box_reg: 0.0081 (0.0102)  time: 0.7497  data: 0.1542  max mem: 8870\n",
      "Epoch: [0]  [ 42/288]  eta: 0:03:27  lr: 0.000753  loss: 0.6035 (1.0862)  loss_classifier: 0.4386 (0.8907)  loss_box_reg: 0.1297 (0.1359)  loss_objectness: 0.0393 (0.0494)  loss_rpn_box_reg: 0.0086 (0.0102)  time: 0.7576  data: 0.1605  max mem: 8870\n",
      "Epoch: [0]  [ 43/288]  eta: 0:03:26  lr: 0.000771  loss: 0.5861 (1.0729)  loss_classifier: 0.4012 (0.8772)  loss_box_reg: 0.1302 (0.1364)  loss_objectness: 0.0393 (0.0491)  loss_rpn_box_reg: 0.0090 (0.0102)  time: 0.7651  data: 0.1620  max mem: 8870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 44/288]  eta: 0:03:25  lr: 0.000788  loss: 0.5784 (1.0578)  loss_classifier: 0.3830 (0.8628)  loss_box_reg: 0.1302 (0.1366)  loss_objectness: 0.0393 (0.0482)  loss_rpn_box_reg: 0.0090 (0.0102)  time: 0.7683  data: 0.1625  max mem: 8870\n"
     ]
    }
   ],
   "source": [
    "train_model(model_resnet_face_classes, dataloaders[\"dataset_big_face_classes\"], SGD(model_resnet_face_classes.parameters(), lr=LEARNING_RATE), num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the models on the big dataset with all classes and single faces\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "models_trained = {}\n",
    "\n",
    "model_type__dataloader_map = {\n",
    "    \"all_classes\": \"dataset_big_all_classes\",\n",
    "    \"face_classes\": \"dataset_big_face_classes\"\n",
    "}\n",
    "\n",
    "\n",
    "for model_name, model_dict in models_classComparison.items():\n",
    "    models_trained[model_name] = {}\n",
    "    for model_type, model in model_dict.items():\n",
    "        \n",
    "        print(\"Training model: \", model_name, \" \", model_type)\n",
    "        print(\"using dataset: \", model_type__dataloader_map[model_type])\n",
    "        print(\"--------------------------------------------------\")\n",
    "        params = [p for p in model.parameters() if p.requires_grad]\n",
    "        optimizer = torch.optim.SGD(params, lr=LEARNING_RATE, momentum=0.9, weight_decay=0.0005)\n",
    "        model, ap_values, ar_values, losses = train_model(model, dataloaders[model_type__dataloader_map[model_type]], optimizer, num_epochs=NUM_EPOCHS)\n",
    "        models_trained[model_name][model_type] = model\n",
    "\n",
    "        # Save the model into the \"finished_models\" folder\n",
    "        model_filename = f\"{model_name}_{model_type}.pth\"\n",
    "        model_path = os.path.join(\"finished_models/class_compare/\", model_filename)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        # Save the metrics into the \"metric_history\" folder\n",
    "        metric_filename = f\"{model_name}_{model_type}_metrics.npz\"\n",
    "        metric_path = os.path.join(\"finished_models/class_compare/metric_history\", metric_filename)\n",
    "        np.savez(metric_path, ap_values=ap_values, ar_values=ar_values, losses=losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DV-STA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
