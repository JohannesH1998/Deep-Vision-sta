{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.models.detection import SSD300_VGG16_Weights\n",
    "from torchvision.models.vgg import VGG16_Weights\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.models.detection import ssd\n",
    "from PIL import Image\n",
    "from torchvision.models.detection import SSDLite320_MobileNet_V3_Large_Weights\n",
    "from torchvision.models import MobileNet_V3_Large_Weights\n",
    "from torchvision.models.detection import ssdlite320_mobilenet_v3_large\n",
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "import utils\n",
    "import PIL.Image\n",
    "import torchvision.transforms.functional as F\n",
    "import xml.etree.ElementTree as ET\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir_json = r\"C:\\Users\\Domi\\Documents\\GitHub\\Deep-Vision-sta\\Datasets\\Face Mask Detection Dataset\\Medical mask\\Medical mask\\Medical Mask\"\n",
    "root_dir_xml = r\"C:\\Users\\Domi\\Documents\\GitHub\\Deep-Vision-sta\\Datasets\\Kaggle Face Mask Detection Full\"\n",
    "\n",
    "\n",
    "#Normalize: True, Batch Size: 1, Momentum: 0.9, Nesterov: True\n",
    "#Normalize: True, Batch Size: 1, Momentum: 0.95, Nesterov: True\n",
    "#Normalize: True, Batch Size: 1, Momentum: 0.95, Nesterov: False\n",
    "#Normalize: True, Batch Size: 2, Momentum: 0.95, Nesterov: True\n",
    "\n",
    "\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "NORMALIZE = False\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "RESIZE = (300, 300)\n",
    "ROUND_RESIZED_BBOXES = False\n",
    "LEARNING_RATE = 0.00001\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 0.0005\n",
    "NESTEROV = True\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "ALLOWED_LABELS = [3, 4, 5, 6]\n",
    "CLASS_MAPPING = {\n",
    "    \"hijab_niqab\": 0,\n",
    "    \"mask_colorful\": 1,\n",
    "    \"mask_surgical\": 2,\n",
    "    \"face_no_mask\": 3,\n",
    "    \"face_with_mask_incorrect\": 4,\n",
    "    \"face_with_mask\": 5,\n",
    "    \"face_other_covering\": 6,\n",
    "    \"scarf_bandana\": 7,\n",
    "    \"balaclava_ski_mask\": 8,\n",
    "    \"face_shield\": 9,\n",
    "    \"other\": 10,\n",
    "    \"gas_mask\": 11,\n",
    "    \"turban\": 12,\n",
    "    \"helmet\": 13,\n",
    "    \"sunglasses\": 14,\n",
    "    \"eyeglasses\": 15,\n",
    "    \"hair_net\": 16,\n",
    "    \"hat\": 17,\n",
    "    \"goggles\": 18,\n",
    "    \"hood\": 19\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATACLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataclass for json annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonDataset(Dataset):\n",
    "    def __init__(self, root_dir, class_mapping, only_single_faces=False, only_multiple_faces=False, target_size=(300,300)):\n",
    "        self.root_dir = root_dir\n",
    "        self.class_label_map = class_mapping\n",
    "        self.annotations = []\n",
    "        self.target_size = target_size\n",
    "        self.only_single_faces = only_single_faces\n",
    "        self.only_multiple_faces = only_multiple_faces\n",
    "        if(self.only_single_faces and self.only_multiple_faces):\n",
    "            raise ValueError(\"only_single_faces and only_multiple_faces cannot both be true\\n Only one of them can be true\")\n",
    "        \n",
    "        self.load_annotations(self.class_label_map.values())\n",
    "\n",
    "    def load_annotations(self, allowed_classes):\n",
    "        annotation_files = os.listdir(f\"{self.root_dir}/annotations\")\n",
    "        for file_name in annotation_files:\n",
    "            with open(f\"{self.root_dir}/annotations/{file_name}\", \"r\") as f:\n",
    "                annotation_data = json.load(f)\n",
    "                annotations = annotation_data[\"Annotations\"]\n",
    "                file_name = annotation_data[\"FileName\"]\n",
    "                #get the allowed class names from the keys of the CLASS_LABELS dictionary\n",
    "                allowed_classnames = [key for key, value in self.class_label_map.items() if value in allowed_classes]\n",
    "                face_classes = [\"face_no_mask\", \"face_with_mask_incorrect\", \"face_with_mask\", \"face_other_covering\"]\n",
    "                annotations = [annotation for annotation in annotations if annotation[\"classname\"] in allowed_classnames]\n",
    "\n",
    "                if self.only_single_faces:\n",
    "                    #check if multiple of the face_classes are present in the annotations, indicating multiple faces\n",
    "                    face_annotations = [annotation for annotation in annotations if annotation[\"classname\"] in face_classes]\n",
    "                    if len(face_annotations) > 1:\n",
    "                        continue \n",
    "                    self.annotations.append((annotations, file_name))\n",
    "\n",
    "                elif self.only_multiple_faces:\n",
    "                    #check if multiple of the face_classes are present in the annotations, indicating multiple faces\n",
    "                    face_annotations = [annotation for annotation in annotations if annotation[\"classname\"] in face_classes]\n",
    "                    if len(face_annotations) <= 1:\n",
    "                        continue\n",
    "                    else:\n",
    "                        self.annotations.append((annotations, file_name))\n",
    "\n",
    "                else:\n",
    "                    if(annotations == []):\n",
    "                        #warnings.warn(f\"File {file_name} has no annotations\")\n",
    "                        continue\n",
    "                    self.annotations.append((annotations, file_name))\n",
    "                # Check if the boxes are valid\n",
    "                for annotation in annotations:\n",
    "                    boxes = annotation[\"BoundingBox\"]\n",
    "                    if boxes[0] >= boxes[2] or boxes[1] >= boxes[3]:\n",
    "                        print(\"Invalid bounding box coordinates in file:\", file_name)\n",
    "                        break\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        annotations = self.annotations[idx][0]\n",
    "        file_name = self.annotations[idx][1]\n",
    "        image_path = f\"{self.root_dir}/images/{file_name}\"\n",
    "        image = PIL.Image.open(image_path).convert(\"RGB\")\n",
    "        original_image_width, original_image_height = image.size\n",
    "        image = F.resize(image, self.target_size)\n",
    "        image = F.to_tensor(image)\n",
    "        if NORMALIZE:\n",
    "            image = F.normalize(image, MEAN, STD)\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for annotation in annotations:\n",
    "            box = annotation[\"BoundingBox\"]\n",
    "            if box[0] < box[2] and box[1] < box[3]:\n",
    "                # Resize the bounding box coordinates\n",
    "                box_resized = [\n",
    "                    box[0] * self.target_size[0] / original_image_width,\n",
    "                    box[1] * self.target_size[1] / original_image_height,\n",
    "                    box[2] * self.target_size[0] / original_image_width,\n",
    "                    box[3] * self.target_size[1] / original_image_height\n",
    "                ]\n",
    "                boxes.append(box_resized)\n",
    "                class_name = annotation[\"classname\"]\n",
    "                # Get the class label based on the class name\n",
    "                class_label = self.get_class_label(class_name)\n",
    "                labels.append(class_label)\n",
    "\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"area\"] = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        target[\"iscrowd\"] = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    \n",
    "    def get_class_label(self, class_name):\n",
    "        return self.class_label_map.get(class_name, -1)  # Return -1 if class_name is not found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataclass for XML Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XMLDataset(Dataset):\n",
    "    def __init__(self, root_dir, class_mapping, target_size=RESIZE, use_dark_images=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.class_mapping = class_mapping\n",
    "        self.annotations = []\n",
    "        self.target_size = target_size\n",
    "        self.use_dark_images = use_dark_images\n",
    "        self.load_annotations()\n",
    "\n",
    "    def load_annotations(self):\n",
    "        annotation_files = os.listdir(f\"{self.root_dir}/annotations\")\n",
    "        for file_name in annotation_files:\n",
    "            with open(f\"{self.root_dir}/annotations/{file_name}\", \"r\") as f:\n",
    "                tree = ET.parse(f)\n",
    "                root = tree.getroot()\n",
    "                annotations = []\n",
    "                for obj in root.findall('object'):\n",
    "                    name = obj.find('name').text\n",
    "                    bndbox = obj.find('bndbox')\n",
    "                    xmin = int(bndbox.find('xmin').text)\n",
    "                    ymin = int(bndbox.find('ymin').text)\n",
    "                    xmax = int(bndbox.find('xmax').text)\n",
    "                    ymax = int(bndbox.find('ymax').text)\n",
    "                    bounding_box = [xmin, ymin, xmax, ymax]\n",
    "                    annotation = {\n",
    "                        \"BoundingBox\": bounding_box,\n",
    "                        \"classname\": name\n",
    "                    }\n",
    "                    annotations.append(annotation)\n",
    "                file_name = root.find('filename').text\n",
    "                self.annotations.append((annotations, file_name))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        annotations = self.annotations[idx][0]\n",
    "        file_name = self.annotations[idx][1]\n",
    "        image_path = f\"{self.root_dir}/images/{file_name}\"\n",
    "        if(self.use_dark_images):\n",
    "            image_path = f\"{self.root_dir}/dark/images/{file_name}\"\n",
    "        image = PIL.Image.open(image_path).convert(\"RGB\")\n",
    "        original_image_width, original_image_height = image.size\n",
    "        image = F.resize(image, self.target_size)\n",
    "        image = F.to_tensor(image)\n",
    "        if NORMALIZE:\n",
    "            image = F.normalize(image, MEAN, STD)\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for annotation in annotations:\n",
    "            box = annotation[\"BoundingBox\"]\n",
    "            if box[0] < box[2] and box[1] < box[3]:\n",
    "                # Resize the bounding box coordinates\n",
    "                box_resized = [\n",
    "                    box[0] * self.target_size[0] / original_image_width,\n",
    "                    box[1] * self.target_size[1] / original_image_height,\n",
    "                    box[2] * self.target_size[0] / original_image_width,\n",
    "                    box[3] * self.target_size[1] / original_image_height\n",
    "                ]\n",
    "                boxes.append(box_resized)\n",
    "                class_name = annotation[\"classname\"]\n",
    "                # Get the class label based on the class name\n",
    "                class_label = self.get_class_label(class_name)\n",
    "                #print(class_name)\n",
    "                labels.append(class_label)\n",
    "\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"area\"] = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        target[\"iscrowd\"] = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def get_class_label(self, class_name):\n",
    "        return self.class_mapping.get(class_name, -1)  # Return -1 if class_name is not found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_image_with_boxes(image, target, class_mapping):    \n",
    "    # Unnormalize the image\n",
    "    if NORMALIZE:\n",
    "        image = transforms.Normalize(mean=[-m / s for m, s in zip(MEAN, STD)], std=[1 / s for s in STD])(image)\n",
    "    image_pil = transforms.ToPILImage()(image)\n",
    "\n",
    "    # Kopiere die Bounding-Box-Koordinaten auf die CPU und konvertiere sie in numpy-Arrays\n",
    "    boxes = target[\"boxes\"]\n",
    "    labels = target[\"labels\"]\n",
    "    boxes = boxes.cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "        \n",
    "    # Erstelle eine neue Figur und Achse\n",
    "    fig, ax = plt.subplots(1)    \n",
    "    # Zeige das Bild in der Achse\n",
    "    ax.imshow(image_pil)    \n",
    "    \n",
    "    # Iteriere über die Bounding-Boxen und zeichne sie als Rechtecke in der Achse\n",
    "    for box, label in zip(boxes, labels):        \n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        class_name = list(class_mapping.keys())[list(class_mapping.values()).index(label)]\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)            \n",
    "        ax.text(x_min, y_min, f\"{class_name}, {label}\", color='r', fontsize=8, bbox=dict(facecolor='white', alpha=0.7, edgecolor='none'))\n",
    "\n",
    "    # Zeige die Achse\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model(batch_size, lr, momentum, nesterov, test_size, dataformat = 'json', model='ssd300', class_mapping=CLASS_MAPPING, use_dark_images=False):\n",
    "\n",
    "    # Modell initialisieren\n",
    "    if model == 'ssd300':\n",
    "        model = ssd.ssd300_vgg16(weights=SSD300_VGG16_Weights.DEFAULT, weights_backbone=VGG16_Weights.DEFAULT)\n",
    "    elif model == 'ssd320lite':\n",
    "        model = ssdlite320_mobilenet_v3_large(weights=SSDLite320_MobileNet_V3_Large_Weights.DEFAULT, weights_backbone=MobileNet_V3_Large_Weights.DEFAULT)\n",
    "\n",
    "    # Daten in Trainings- und Testdaten aufteilen\n",
    "    if dataformat == 'json':            \n",
    "        dataset = JsonDataset(root_dir_json, class_mapping, target_size=RESIZE)\n",
    "    elif dataformat == 'xml':\n",
    "        dataset = XMLDataset(root_dir_xml, class_mapping, target_size=RESIZE, use_dark_images=use_dark_images)\n",
    "        \n",
    "    train_size = int((1-test_size) * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    # Trainingsdaten vorbereiten und DataLoader erstellen\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=utils.collate_fn)\n",
    "\n",
    "    # Testdaten vorbereiten und DataLoader erstellen\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=utils.collate_fn)\n",
    "\n",
    "    # Optimizer erstellen\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, nesterov=nesterov)    \n",
    "\n",
    "    return model, train_dataloader, test_dataloader, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path, name, class_mapping, ap_values, ar_values, losses, hyperparameters):\n",
    "    # Erstelle den Ordner mit dem Namen des Modells\n",
    "    model_dir = os.path.join(path, name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Speichere das Zustandsdictionary des Modells\n",
    "    model_path = os.path.join(model_dir, name + \".pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    # Konvertiere NumPy-Arrays in reguläre Python-Listen\n",
    "    ap_values = [ap.tolist() for ap in ap_values]\n",
    "    ar_values = [ar.tolist() for ar in ar_values]\n",
    "    losses = [float(loss) for loss in losses]\n",
    "\n",
    "    # Speichere Metadaten in einer JSON-Datei\n",
    "    metadata = {\n",
    "        \"class_mapping\": class_mapping,\n",
    "        \"ap_values\": ap_values,\n",
    "        \"ar_values\": ar_values,\n",
    "        \"losses\": losses,\n",
    "        \"hyperparameters\": hyperparameters\n",
    "    }\n",
    "    metadata_path = os.path.join(model_dir, name + \".json\")\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump(metadata, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_val_dataset(filter_classes, dataformat = 'json', class_mapping=CLASS_MAPPING):\n",
    "     # Daten in Trainings- und Testdaten aufteilen\n",
    "    if dataformat == 'json':            \n",
    "        dataset = JsonDataset(root_dir_json, RESIZE, class_mapping, filter_classes)\n",
    "    elif dataformat == 'xml':\n",
    "        dataset = XMLDataset(root_dir_xml, RESIZE, class_mapping)\n",
    "        \n",
    "    train_size = 0\n",
    "    val_size = len(dataset)\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_training(model, train_dataloader, test_dataloader, optimizer, device, num_epochs=2):\n",
    "    # # Trainingsschleife\n",
    "    model.to(device)\n",
    "\n",
    "    # Define empty arrays to collect metrics\n",
    "    ap_values = []\n",
    "    ar_values = []\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # training for one epoch\n",
    "        train_one_epoch(model, optimizer, train_dataloader, device, epoch, print_freq=1, losses_out=losses)\n",
    "\n",
    "        # update the learning rate\n",
    "        # lr_scheduler.step()\n",
    "        \n",
    "        # evaluate on the test dataset        \n",
    "        evaluator = evaluate(model, test_dataloader, device=device)\n",
    "\n",
    "        # Extract the metrics from the evaluator\n",
    "        iou_thresholds = evaluator.coco_eval['bbox'].params.iouThrs\n",
    "        average_precisions = evaluator.coco_eval['bbox'].stats[:6]\n",
    "        average_recalls = evaluator.coco_eval['bbox'].stats[6:]\n",
    "\n",
    "        # Append the metrics to the arrays\n",
    "        ap_values.append(average_precisions)\n",
    "        ar_values.append(average_recalls)\n",
    "    \n",
    "    return ap_values, ar_values, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_losses):\n",
    "    plt.plot(train_losses)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    average_loss = sum(train_losses)/len(train_losses)\n",
    "    print(\"Average Loss: \", average_loss)\n",
    "    print(\"last Loss: \", train_losses[-1])\n",
    "\n",
    "\n",
    "\n",
    "def plot_metrics(ap_values, ar_values):\n",
    "    # Convert the arrays to numpy arrays for easier plotting\n",
    "    ap_values = np.array(ap_values)\n",
    "    ar_values = np.array(ar_values)\n",
    "\n",
    "    iou_thresholds_available = [\"0.50:0.95\", \"0.50\", \"0.75\", \"0.50:0.95_small\", \"0.50:0.95_medium\", \"0.50:0.95_large\"]\n",
    "\n",
    "    # Plot the average precisions over epochs\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, iou_thresh in enumerate(iou_thresholds_available):\n",
    "        plt.plot(ap_values[:, i], label=f\"IoU={iou_thresh}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Average Precision\")\n",
    "    plt.title(\"Average Precision vs. Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the average recalls over epochs\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, iou_thresh in enumerate(iou_thresholds_available):\n",
    "        plt.plot(ar_values[:, i], label=f\"IoU={iou_thresh}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Average Recall\")\n",
    "    plt.title(\"Average Recall vs. Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(\"Average Precisions: \", ap_values[-1])\n",
    "    print(\"Max Precision: \", ap_values.max())\n",
    "    print(\"Average Recalls: \", ar_values[-1])\n",
    "    print(\"Max Recall: \", ar_values.max())\n",
    "\n",
    "    \n",
    "\n",
    "def visualize_prediction(images, model, confidence_threshold, device, allowed_labels, class_mapping):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    if len(images) == 1:\n",
    "        # Batch size is 1\n",
    "        image = images[0].to(device)\n",
    "        # Perform inference for a single image\n",
    "        with torch.no_grad():\n",
    "            predictions = model([image])\n",
    "    else:\n",
    "        # Batch size > 1\n",
    "        imgs = list(image.to(device) for image in images)\n",
    "        # Perform inference for the batch\n",
    "        with torch.no_grad():\n",
    "            predictions = model(imgs)\n",
    "            # Perform inference\n",
    "    \n",
    "\n",
    "    for image, prediction in zip(images, predictions):\n",
    "        if NORMALIZE:\n",
    "            # Unnormalize the image\n",
    "            image = F.normalize(image, mean=[-m / s for m, s in zip(MEAN, STD)], std=[1 / s for s in STD])\n",
    "            #image = F.normalize(image, mean=MEAN, std=STD)\n",
    "        # Convert the image tensor to a PIL Image\n",
    "        image_pil = transforms.ToPILImage()(image)\n",
    "\n",
    "        # Get the predicted bounding boxes, labels, and scores\n",
    "        boxes = prediction['boxes'].cpu().numpy()\n",
    "        labels = prediction['labels'].cpu().numpy()\n",
    "        scores = prediction['scores'].cpu().numpy()\n",
    "\n",
    "        # Visualize the image and predicted bounding boxes\n",
    "        fig, ax = plt.subplots(1)\n",
    "        ax.imshow(image_pil)\n",
    "\n",
    "        for box, label, score in zip(boxes, labels, scores):\n",
    "            if label in allowed_labels and score > confidence_threshold:\n",
    "                x_min, y_min, x_max, y_max = box\n",
    "                width = x_max - x_min\n",
    "                height = y_max - y_min\n",
    "                class_name = list(class_mapping.keys())[list(class_mapping.values()).index(label)]\n",
    "                rect = patches.Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "                ax.text(x_min, y_min, f\"{class_name}, {label}\", color='r', fontsize=8, bbox=dict(facecolor='white', alpha=0.7, edgecolor='none'))\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter optimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def optimize_params(normalize_options = [True, False], batch_size_options = [1], momentum_options = [0.9, 0.95], nesterov_options = [True, False]):\n",
    "    # Erzeuge alle möglichen Kombinationen der Hyperparameter\n",
    "    hyperparameter_combinations = list(itertools.product(batch_size_options, momentum_options, nesterov_options, normalize_options))\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "    best_hyperparameters = None\n",
    "\n",
    "    # Durchlaufe alle Kombinationen und trainiere das Modell mit jeder Kombination\n",
    "    for batch_size, momentum, nesterov_options, normalize in hyperparameter_combinations:\n",
    "        # Setze die Hyperparameter auf die aktuellen Werte\n",
    "        NORMALIZE = normalize\n",
    "        BATCH_SIZE = batch_size\n",
    "        MOMENTUM = momentum\n",
    "        NESTEROV = nesterov_options\n",
    "        print(f\"Normalize: {normalize}, Batch Size: {batch_size}, Momentum: {momentum}, Nesterov: {nesterov_options}\")\n",
    "        # Erstelle das Modell und den Optimizer mit den aktuellen Hyperparametern\n",
    "        model, train_dataloader, test_dataloader, optimizer = setup_model(BATCH_SIZE, \n",
    "                                                        weights_backbone=VGG16_Weights.DEFAULT, \n",
    "                                                        weights=SSD300_VGG16_Weights.DEFAULT,                                                        \n",
    "                                                        lr=LEARNING_RATE,\n",
    "                                                        momentum=MOMENTUM,                                                        \n",
    "                                                        nesterov=NESTEROV,\n",
    "                                                        test_size=TEST_SIZE)\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        ap_values, ar_values, losses = start_training(model, train_dataloader, test_dataloader, optimizer, device=device, num_epochs=NUM_EPOCHS)\n",
    "        plot_loss(losses)\n",
    "        plot_metrics(ap_values, ar_values)\n",
    "\n",
    "        # Bewerte die Leistung des Modells (z. B. Genauigkeit)\n",
    "        accuracy = np.max(ar_values)\n",
    "\n",
    "        # Speichere die besten Hyperparameter\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_hyperparameters = (normalize, batch_size, momentum, nesterov_options)\n",
    "        print(f\"Beste Hyperparameter: {best_hyperparameters} \\n Best Accuracy: {best_accuracy}\")\n",
    "\n",
    "    print(f\"FINAL!!!!\\nBeste Hyperparameter: {best_hyperparameters} \\n Best Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Train SSD300_VGG16 on Json Model on 4 classes only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize: True, Batch Size: 1, Momentum: 0.9, Nesterov: True\n",
    "Normalize: True, Batch Size: 1, Momentum: 0.95, Nesterov: True\n",
    "Normalize: True, Batch Size: 1, Momentum: 0.95, Nesterov: False\n",
    "Normalize: True, Batch Size: 2, Momentum: 0.95, Nesterov: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "MOMENTUM = 0.9\n",
    "NESTEROV = True\n",
    "NORMALIZE = True\n",
    "RESIZE = (300, 300)\n",
    "\n",
    "class_label_mapping = {\n",
    "    \"empty\": 0,\n",
    "    \"face_no_mask\": 1,\n",
    "    \"face_with_mask_incorrect\": 2,\n",
    "    \"face_with_mask\": 3,\n",
    "    \"face_other_covering\": 4,\n",
    "}\n",
    "\n",
    "model, train_dataloader, test_dataloader, optimizer = setup_model(BATCH_SIZE,                                                                                                                        \n",
    "                                                                lr=LEARNING_RATE,\n",
    "                                                                momentum=MOMENTUM,                                                       \n",
    "                                                                nesterov=NESTEROV,\n",
    "                                                                test_size=TEST_SIZE,\n",
    "                                                                class_mapping=class_label_mapping,                                                                \n",
    "                                                                dataformat='json', \n",
    "                                                                model='ssd300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ap_values, ar_values, losses = start_training(model, train_dataloader, test_dataloader, optimizer, device=device, num_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = next(iter(test_dataloader))\n",
    "\n",
    "visualize_prediction(samples[0], model, 0.5, device, class_label_mapping.values(), class_label_mapping)\n",
    "draw_image_with_boxes(samples[0][0], samples[1][0], class_label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(losses)\n",
    "plot_metrics(ap_values, ar_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, \"models/\", \"ssd300_vgg16_4_classes\", class_label_mapping, ap_values, ar_values, losses, hyperparameters=(BATCH_SIZE, MOMENTUM, NESTEROV, NORMALIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup SDD300_VGG16 Model on Json Dataset with all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    \"empty\": 0,\n",
    "    \"hijab_niqab\": 1,\n",
    "    \"mask_colorful\": 2,\n",
    "    \"mask_surgical\": 3,\n",
    "    \"face_no_mask\": 4,\n",
    "    \"face_with_mask_incorrect\": 5,\n",
    "    \"face_with_mask\": 6,\n",
    "    \"face_other_covering\": 7,\n",
    "    \"scarf_bandana\": 8,\n",
    "    \"balaclava_ski_mask\": 9,\n",
    "    \"face_shield\": 10,\n",
    "    \"other\": 11,\n",
    "    \"gas_mask\": 12,\n",
    "    \"turban\": 13,\n",
    "    \"helmet\": 14,\n",
    "    \"sunglasses\": 15,\n",
    "    \"eyeglasses\": 16,\n",
    "    \"hair_net\": 17,\n",
    "    \"hat\": 18,\n",
    "    \"goggles\": 19,\n",
    "    \"hood\": 20\n",
    "}\n",
    "\n",
    "\n",
    "NORMALIZE = True\n",
    "BATCH_SIZE = 1\n",
    "MOMENTUM = 0.9\n",
    "NESTEROV = True\n",
    "RESIZE = (300, 300)\n",
    "\n",
    "model, train_dataloader, test_dataloader, optimizer = setup_model(batch_size=BATCH_SIZE,                                                                                                                        \n",
    "                                                                lr=0.00001,\n",
    "                                                                momentum=MOMENTUM,                                                       \n",
    "                                                                nesterov=NESTEROV,\n",
    "                                                                test_size=TEST_SIZE,\n",
    "                                                                class_mapping=class_mapping,                                                                \n",
    "                                                                dataformat='json', \n",
    "                                                                model='ssd300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ap_values, ar_values, losses = start_training(model, train_dataloader, test_dataloader, optimizer, device=device, num_epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = next(iter(test_dataloader))\n",
    "visualize_prediction(samples[0], model, 0.5, device, class_mapping.values(), class_mapping)\n",
    "draw_image_with_boxes(samples[0][0], samples[1][0], class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(losses)\n",
    "plot_metrics(ap_values, ar_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, \"models/\", \"ssd300_vgg16_all_classes\", class_mapping, ap_values, ar_values, losses, hyperparameters=(BATCH_SIZE, MOMENTUM, NESTEROV, NORMALIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup SDD320lite_MobileNetV3 Model on Json Dataset with 4 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_mapping = {\n",
    "    \"empty\": 0,\n",
    "    \"face_no_mask\": 1,\n",
    "    \"face_with_mask_incorrect\": 2,\n",
    "    \"face_with_mask\": 3,\n",
    "    \"face_other_covering\": 4,\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "MOMENTUM = 0.9\n",
    "NESTEROV = True\n",
    "NORMALIZE = True\n",
    "RESIZE = 320\n",
    "\n",
    "model, train_dataloader, test_dataloader, optimizer = setup_model(batch_size=BATCH_SIZE,                                                                                                                        \n",
    "                                                                lr=LEARNING_RATE,\n",
    "                                                                momentum=MOMENTUM,                                                       \n",
    "                                                                nesterov=NESTEROV,\n",
    "                                                                test_size=TEST_SIZE,\n",
    "                                                                class_mapping=class_label_mapping,                                                                \n",
    "                                                                dataformat='json', \n",
    "                                                                model='ssd320lite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ap_values, ar_values, losses = start_training(model, train_dataloader, test_dataloader, optimizer, device=device, num_epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = next(iter(test_dataloader))\n",
    "visualize_prediction(samples[0], model, 0.5, device, class_label_mapping.values(), class_label_mapping)\n",
    "draw_image_with_boxes(samples[0][0], samples[1][0], class_label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(losses)\n",
    "plot_metrics(ap_values, ar_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, \"models/\", \"ssd320lite_MobielNetV3_4_classes\", class_label_mapping, ap_values, ar_values, losses, hyperparameters=(BATCH_SIZE, MOMENTUM, NESTEROV, NORMALIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup SDD320lite_MobileNetV3 Model on Json Dataset with all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    \"empty\": 0,\n",
    "    \"hijab_niqab\": 1,\n",
    "    \"mask_colorful\": 2,\n",
    "    \"mask_surgical\": 3,\n",
    "    \"face_no_mask\": 4,\n",
    "    \"face_with_mask_incorrect\": 5,\n",
    "    \"face_with_mask\": 6,\n",
    "    \"face_other_covering\": 7,\n",
    "    \"scarf_bandana\": 8,\n",
    "    \"balaclava_ski_mask\": 9,\n",
    "    \"face_shield\": 10,\n",
    "    \"other\": 11,\n",
    "    \"gas_mask\": 12,\n",
    "    \"turban\": 13,\n",
    "    \"helmet\": 14,\n",
    "    \"sunglasses\": 15,\n",
    "    \"eyeglasses\": 16,\n",
    "    \"hair_net\": 17,\n",
    "    \"hat\": 18,\n",
    "    \"goggles\": 19,\n",
    "    \"hood\": 20\n",
    "}\n",
    "\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "MOMENTUM = 0.9\n",
    "NESTEROV = True\n",
    "NORMALIZE = True\n",
    "RESIZE = 320\n",
    "\n",
    "model, train_dataloader, test_dataloader, optimizer = setup_model(batch_size=BATCH_SIZE,                                                                                                                        \n",
    "                                                                lr=LEARNING_RATE,\n",
    "                                                                momentum=MOMENTUM,                                                       \n",
    "                                                                nesterov=NESTEROV,\n",
    "                                                                test_size=TEST_SIZE,\n",
    "                                                                class_mapping=class_mapping,                                                                \n",
    "                                                                dataformat='json', \n",
    "                                                                model='ssd320lite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ap_values, ar_values, losses = start_training(model, train_dataloader, test_dataloader, optimizer, device=device, num_epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = next(iter(test_dataloader))\n",
    "visualize_prediction(samples[0], model, 0.5, device, class_mapping.values(), class_mapping)\n",
    "draw_image_with_boxes(samples[0][0], samples[1][0], class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(losses)\n",
    "plot_metrics(ap_values, ar_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, \"models/\", \"ssd320lite_MobielNetV3_all_classes\", class_mapping, ap_values, ar_values, losses, hyperparameters=(BATCH_SIZE, MOMENTUM, NESTEROV, NORMALIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup SDD300_VGG16 Model on XML Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping_xml = {\n",
    "    \"empty\": 0,\n",
    "    \"without_mask\": 1,\n",
    "    \"with_mask\": 2,\n",
    "    \"mask_weared_incorrect\": 3,\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "MOMENTUM = 0.9\n",
    "NESTEROV = True\n",
    "NORMALIZE = True\n",
    "RESIZE = 300\n",
    "\n",
    "model, train_dataloader, test_dataloader, optimizer = setup_model(BATCH_SIZE,                                                                                                                        \n",
    "                                                                lr=LEARNING_RATE,\n",
    "                                                                momentum=MOMENTUM,                                                       \n",
    "                                                                nesterov=NESTEROV,\n",
    "                                                                test_size=TEST_SIZE,\n",
    "                                                                class_mapping=class_mapping_xml,                                                                \n",
    "                                                                dataformat='xml', \n",
    "                                                                model='ssd300')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ap_values, ar_values, losses = start_training(model, train_dataloader, test_dataloader, optimizer, device=device, num_epochs=12)\n",
    "\n",
    "samples = next(iter(test_dataloader))\n",
    "visualize_prediction(samples[0], model, 0.5, device, class_mapping_xml.values(), class_mapping_xml)\n",
    "draw_image_with_boxes(samples[0][0], samples[1][0], class_mapping_xml)\n",
    "\n",
    "plot_loss(losses)\n",
    "plot_metrics(ap_values, ar_values)\n",
    "\n",
    "save_model(model, \"models/\", \"ssd300_vgg16_XML_Dataset\", class_mapping_xml, ap_values, ar_values, losses, hyperparameters=(BATCH_SIZE, MOMENTUM, NESTEROV, NORMALIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup SDD320lite_MobileNetV3 Model on XML Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping_xml = {\n",
    "    \"empty\": 0,\n",
    "    \"without_mask\": 1,\n",
    "    \"with_mask\": 2,\n",
    "    \"mask_weared_incorrect\": 3,\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "MOMENTUM = 0.9\n",
    "NESTEROV = True\n",
    "NORMALIZE = True\n",
    "RESIZE = 320\n",
    "\n",
    "model, train_dataloader, test_dataloader, optimizer = setup_model(BATCH_SIZE,                                                                                                                        \n",
    "                                                                lr=LEARNING_RATE,\n",
    "                                                                momentum=MOMENTUM,                                                       \n",
    "                                                                nesterov=NESTEROV,\n",
    "                                                                test_size=TEST_SIZE,\n",
    "                                                                class_mapping=class_mapping_xml,                                                                \n",
    "                                                                dataformat='xml', \n",
    "                                                                model='ssd320lite')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ap_values, ar_values, losses = start_training(model, train_dataloader, test_dataloader, optimizer, device=device, num_epochs=12)\n",
    "\n",
    "plot_loss(losses)\n",
    "plot_metrics(ap_values, ar_values)\n",
    "\n",
    "save_model(model, \"models/\", \"ssd320lite_MobielNetV3_XML_Dataset\", class_mapping_xml, ap_values, ar_values, losses, hyperparameters=(BATCH_SIZE, MOMENTUM, NESTEROV, NORMALIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = next(iter(test_dataloader))\n",
    "visualize_prediction(samples[0], model, 0.5, device, class_mapping_xml.values(), class_mapping_xml)\n",
    "draw_image_with_boxes(samples[0][0], samples[1][0], class_mapping_xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup SDD300_VGG16 Model on Dark XML Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping_xml = {\n",
    "    \"empty\": 0,\n",
    "    \"without_mask\": 1,\n",
    "    \"with_mask\": 2,\n",
    "    \"mask_weared_incorrect\": 3,\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "MOMENTUM = 0.9\n",
    "NESTEROV = True\n",
    "NORMALIZE = True\n",
    "RESIZE = 300\n",
    "\n",
    "model, train_dataloader, test_dataloader, optimizer = setup_model(BATCH_SIZE,                                                                                                                        \n",
    "                                                                lr=LEARNING_RATE,\n",
    "                                                                momentum=MOMENTUM,                                                       \n",
    "                                                                nesterov=NESTEROV,\n",
    "                                                                test_size=TEST_SIZE,\n",
    "                                                                class_mapping=class_mapping_xml,                                                                \n",
    "                                                                dataformat='xml', \n",
    "                                                                model='ssd300',\n",
    "                                                                use_dark_images=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ap_values, ar_values, losses = start_training(model, train_dataloader, test_dataloader, optimizer, device=device, num_epochs=12)\n",
    "\n",
    "plot_loss(losses)\n",
    "plot_metrics(ap_values, ar_values)\n",
    "\n",
    "save_model(model, \"models/\", \"ssd300_vgg16_Dark_XML_Dataset\", class_mapping_xml, ap_values, ar_values, losses, hyperparameters=(BATCH_SIZE, MOMENTUM, NESTEROV, NORMALIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = next(iter(test_dataloader))\n",
    "visualize_prediction(samples[0], model, 0.5, device, class_mapping_xml.values(), class_mapping_xml)\n",
    "draw_image_with_boxes(samples[0][0], samples[1][0], class_mapping_xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup SDD320lite_MobileNetV3 Model on Dark XML Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping_xml = {\n",
    "    \"empty\": 0,\n",
    "    \"without_mask\": 1,\n",
    "    \"with_mask\": 2,\n",
    "    \"mask_weared_incorrect\": 3,\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "MOMENTUM = 0.9\n",
    "NESTEROV = True\n",
    "NORMALIZE = True\n",
    "RESIZE = 320\n",
    "\n",
    "model, train_dataloader, test_dataloader, optimizer = setup_model(BATCH_SIZE,                                                                                                                        \n",
    "                                                                lr=LEARNING_RATE,\n",
    "                                                                momentum=MOMENTUM,                                                       \n",
    "                                                                nesterov=NESTEROV,\n",
    "                                                                test_size=TEST_SIZE,\n",
    "                                                                class_mapping=class_mapping_xml,                                                                \n",
    "                                                                dataformat='xml', \n",
    "                                                                model='ssd320lite')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ap_values, ar_values, losses = start_training(model, train_dataloader, test_dataloader, optimizer, device=device, num_epochs=12)\n",
    "\n",
    "plot_loss(losses)\n",
    "plot_metrics(ap_values, ar_values)\n",
    "\n",
    "save_model(model, \"models/\", \"ssd320lite_MobielNetV3_Dark_XML_Dataset\", class_mapping_xml, ap_values, ar_values, losses, hyperparameters=(BATCH_SIZE, MOMENTUM, NESTEROV, NORMALIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = next(iter(test_dataloader))\n",
    "visualize_prediction(samples[0], model, 0.5, device, class_mapping_xml.values(), class_mapping_xml)\n",
    "draw_image_with_boxes(samples[0][0], samples[1][0], class_mapping_xml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
