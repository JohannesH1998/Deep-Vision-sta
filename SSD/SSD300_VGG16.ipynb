{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.models.detection import SSD300_VGG16_Weights\n",
    "from torchvision.models.vgg import VGG16_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.models.detection import ssd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import PIL.Image\n",
    "import torchvision.transforms.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r\"C:\\Users\\Domi\\Documents\\GitHub\\Deep-Vision-sta\\Datasets\\Face Mask Detection Dataset\\Medical mask\\Medical mask\\Medical Mask\"\n",
    "\n",
    "\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "NORMALIZE = False\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "RESIZE = (300, 300)\n",
    "ROUND_RESIZED_BBOXES = False\n",
    "LEARNING_RATE = 0.00001\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 0.0005\n",
    "NESTEROV = True\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "ALLOWED_LABELS = [3, 4, 5, 6]\n",
    "class_mapping = {\n",
    "    \"hijab_niqab\": 0,\n",
    "    \"mask_colorful\": 1,\n",
    "    \"mask_surgical\": 2,\n",
    "    \"face_no_mask\": 3,\n",
    "    \"face_with_mask_incorrect\": 4,\n",
    "    \"face_with_mask\": 5,\n",
    "    \"face_other_covering\": 6,\n",
    "    \"scarf_bandana\": 7,\n",
    "    \"balaclava_ski_mask\": 8,\n",
    "    \"face_shield\": 9,\n",
    "    \"other\": 10,\n",
    "    \"gas_mask\": 11,\n",
    "    \"turban\": 12,\n",
    "    \"helmet\": 13,\n",
    "    \"sunglasses\": 14,\n",
    "    \"eyeglasses\": 15,\n",
    "    \"hair_net\": 16,\n",
    "    \"hat\": 17,\n",
    "    \"goggles\": 18,\n",
    "    \"hood\": 19\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATACLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDetectionDataset(Dataset):\n",
    "    def __init__(self, root_dir, target_size=(600, 900)):\n",
    "        self.root_dir = root_dir\n",
    "        self.annotations = []\n",
    "        self.target_size = target_size\n",
    "        self.load_annotations()\n",
    "\n",
    "    def load_annotations(self):\n",
    "        annotation_files = os.listdir(f\"{self.root_dir}/annotations\")\n",
    "        for file_name in annotation_files:\n",
    "            with open(f\"{self.root_dir}/annotations/{file_name}\", \"r\") as f:\n",
    "                annotation_data = json.load(f)\n",
    "                annotations = annotation_data[\"Annotations\"]\n",
    "                file_name = annotation_data[\"FileName\"]\n",
    "                self.annotations.append((annotations, file_name))\n",
    "                # Check if the boxes are valid\n",
    "                for annotation in annotations:\n",
    "                    boxes = annotation[\"BoundingBox\"]\n",
    "                    if boxes[0] >= boxes[2] or boxes[1] >= boxes[3]:\n",
    "                        print(\"Invalid bounding box coordinates in file:\", file_name)\n",
    "                        break\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        annotations = self.annotations[idx][0]\n",
    "        file_name = self.annotations[idx][1]\n",
    "        image_path = f\"{self.root_dir}/images/{file_name}\"\n",
    "        image = PIL.Image.open(image_path).convert(\"RGB\")\n",
    "        original_image_width, original_image_height = image.size\n",
    "        image = F.resize(image, self.target_size)\n",
    "        image = F.to_tensor(image)\n",
    "        if NORMALIZE:\n",
    "            image = F.normalize(image, MEAN, STD)\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for annotation in annotations:\n",
    "            box = annotation[\"BoundingBox\"]\n",
    "            if box[0] < box[2] and box[1] < box[3]:\n",
    "                # Resize the bounding box coordinates\n",
    "                box_resized = [\n",
    "                    box[0] * self.target_size[0] / original_image_width,\n",
    "                    box[1] * self.target_size[1] / original_image_height,\n",
    "                    box[2] * self.target_size[0] / original_image_width,\n",
    "                    box[3] * self.target_size[1] / original_image_height\n",
    "                ]\n",
    "                boxes.append(box_resized)\n",
    "                class_name = annotation[\"classname\"]\n",
    "                # Get the class label based on the class name\n",
    "                class_label = self.get_class_label(class_name)\n",
    "                labels.append(class_label)\n",
    "\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"area\"] = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        target[\"iscrowd\"] = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    \n",
    "    def get_class_label(self, class_name):\n",
    "        return class_mapping.get(class_name, -1)  # Return -1 if class_name is not found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "def setup_model(batch_size, lr, momentum, weight_decay, nesterov, test_size, weights_backbone=None, weights=None,):\n",
    "    # Modell initialisieren\n",
    "    model = ssd.ssd300_vgg16(weights=weights, weights_backbone=weights_backbone)\n",
    "\n",
    "    # Daten in Trainings- und Testdaten aufteilen    \n",
    "    dataset = MaskDetectionDataset(root_dir, RESIZE)\n",
    "    train_size = int((1-test_size) * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    # Trainingsdaten vorbereiten und DataLoader erstellen\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=utils.collate_fn)\n",
    "\n",
    "    # Testdaten vorbereiten und DataLoader erstellen\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=utils.collate_fn)\n",
    "\n",
    "    # Optimizer erstellen\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, nesterov=nesterov)    \n",
    "\n",
    "    return model, train_dataloader, test_dataloader, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample(dataloader, x):\n",
    "    # Rufen Sie das x-te Element aus dem Dataloader ab\n",
    "    x -=1 \n",
    "    images, annotations = next(iter(dataloader))\n",
    "    image = transforms.ToPILImage(images[x])\n",
    "    boxes = annotations[x]['annotations']\n",
    "    labels = [box['label'] for box in boxes]\n",
    "    print(labels)\n",
    "    # Erstellen Sie eine neue Figur und Achse\n",
    "    fig, ax = plt.subplots(1)\n",
    "    # Zeigen Sie das Bild in der Achse an\n",
    "    ax.imshow(image.permute(1, 2, 0))\n",
    "    # Iterieren Sie über die Bounding Boxes und zeichnen Sie sie als Rechtecke in der Achse\n",
    "    for box, label in (boxes, labels):\n",
    "        x_min, y_min, x_max, y_max = box['bbox']\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        #print(width, height)\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        #ax.text(x_min, y_min, f\"Label: {class_mapping[label]}\", color='r', fontsize=8, bbox=dict(facecolor='white', alpha=0.7, edgecolor='none'))\n",
    "        ax.text(x_min, y_min, f\"{label}\", color='r', fontsize=8, bbox=dict(facecolor='white', alpha=0.7, edgecolor='none'))\n",
    "    # Zeigen Sie die visualisierten Bounding Boxes an\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def draw_image_with_boxes(image, target):    \n",
    "    # Unnormalize the image\n",
    "    if NORMALIZE:\n",
    "        image = transforms.Normalize(mean=[-m / s for m, s in zip(MEAN, STD)], std=[1 / s for s in STD])(image)\n",
    "    image_pil = transforms.ToPILImage()(image)\n",
    "\n",
    "    # Kopiere die Bounding-Box-Koordinaten auf die CPU und konvertiere sie in numpy-Arrays\n",
    "    boxes = target[\"boxes\"]\n",
    "    labels = target[\"labels\"]\n",
    "    boxes = boxes.cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "        \n",
    "    # Erstelle eine neue Figur und Achse\n",
    "    fig, ax = plt.subplots(1)    \n",
    "    # Zeige das Bild in der Achse\n",
    "    ax.imshow(image_pil)\n",
    "    print(target)\n",
    "    \n",
    "    # Iteriere über die Bounding-Boxen und zeichne sie als Rechtecke in der Achse\n",
    "    for box, label in zip(boxes, labels):\n",
    "        for label in ALLOWED_LABELS:\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "            width = x_max - x_min\n",
    "            height = y_max - y_min\n",
    "            rect = patches.Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(x_min, y_min, f\"Label: {class_mapping[label]}\", color='r', fontsize=8, bbox=dict(facecolor='white', alpha=0.7, edgecolor='none'))\n",
    "    # Zeige die Achse\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_prediction(images, model, confidence_threshold, counter = 10):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval() \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        predictions = model(images)\n",
    "        #good = torch.argwhere(scores > confidence_threshold)\n",
    "\n",
    "    for image, prediction in zip(images, predictions):\n",
    "        if NORMALIZE:\n",
    "            # Unnormalize the image\n",
    "            image = transforms.Normalize(mean=[-m / s for m, s in zip(MEAN, STD)], std=[1 / s for s in STD])(image)\n",
    "        image_pil = transforms.ToPILImage()(image)\n",
    "\n",
    "        # Get the predicted bounding boxes, labels, and scores\n",
    "        boxes = prediction['boxes'].cpu().numpy()\n",
    "        labels = prediction['labels'].cpu().numpy()\n",
    "        scores = prediction['scores'].cpu().numpy()\n",
    "\n",
    "        # Visualize the image and predicted bounding boxes\n",
    "        fig, ax = plt.subplots(1)\n",
    "        ax.imshow(image_pil)\n",
    "        allowed_labels = [3, 4, 5, 6]\n",
    "\n",
    "        for box, label, score in zip(boxes, labels, scores):\n",
    "            if label in allowed_labels and score > confidence_threshold and counter%10 == 0:\n",
    "                x_min, y_min, x_max, y_max = box\n",
    "                width = x_max - x_min\n",
    "                height = y_max - y_min\n",
    "                class_name = list(class_mapping.keys())[list(class_mapping.values()).index(label)]\n",
    "                rect = patches.Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "                ax.text(x_min, y_min, f\"{class_name}: {score}\", color='r', fontsize=8, bbox=dict(facecolor='white', alpha=0.7, edgecolor='none'))\n",
    "                counter=0\n",
    "        plt.show()\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_sample(train_dataloader, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def plot_loss(train_losses):\n",
    "    plt.plot(train_losses)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_metrics(ap_values, ar_values):\n",
    "    # Convert the arrays to numpy arrays for easier plotting\n",
    "    ap_values = np.array(ap_values)\n",
    "    ar_values = np.array(ar_values)\n",
    "\n",
    "    iou_thresholds_available = [\"0.50:0.95\", \"0.50\", \"0.75\", \"0.50:0.95_small\", \"0.50:0.95_medium\", \"0.50:0.95_large\"]\n",
    "\n",
    "    # Plot the average precisions over epochs\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, iou_thresh in enumerate(iou_thresholds_available):\n",
    "        plt.plot(ap_values[:, i], label=f\"IoU={iou_thresh}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Average Precision\")\n",
    "    plt.title(\"Average Precision vs. Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the average recalls over epochs\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, iou_thresh in enumerate(iou_thresholds_available):\n",
    "        plt.plot(ar_values[:, i], label=f\"IoU={iou_thresh}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Average Recall\")\n",
    "    plt.title(\"Average Recall vs. Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_prediction(images, model, confidence_threshold, device, allowed_labels = [3, 4, 5, 6]):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Preprocess the images\n",
    "    ims = list(image.to(device) for image in images)\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        predictions = model(ims)\n",
    "        #good = torch.argwhere(scores > confidence_threshold)\n",
    "        #print(predictions)\n",
    "\n",
    "    for image, prediction in zip(images, predictions):\n",
    "        if NORMALIZE:\n",
    "            # Unnormalize the image\n",
    "            image = F.normalize(mean=[-m / s for m, s in zip(MEAN, STD)], std=[1 / s for s in STD])(image)\n",
    "        # Convert the image tensor to a PIL Image\n",
    "        image_pil = transforms.ToPILImage()(image)\n",
    "\n",
    "        # Get the predicted bounding boxes, labels, and scores\n",
    "        boxes = prediction['boxes'].cpu().numpy()\n",
    "        labels = prediction['labels'].cpu().numpy()\n",
    "        scores = prediction['scores'].cpu().numpy()\n",
    "\n",
    "        # Visualize the image and predicted bounding boxes\n",
    "        fig, ax = plt.subplots(1)\n",
    "        ax.imshow(image_pil)\n",
    "\n",
    "        for box, label, score in zip(boxes, labels, scores):\n",
    "            if label in allowed_labels and score > confidence_threshold:\n",
    "                x_min, y_min, x_max, y_max = box\n",
    "                width = x_max - x_min\n",
    "                height = y_max - y_min\n",
    "                class_name = list(class_mapping.keys())[list(class_mapping.values()).index(label)]\n",
    "                rect = patches.Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "                ax.text(x_min, y_min, f\"{class_name}\", color='r', fontsize=8, bbox=dict(facecolor='white', alpha=0.7, edgecolor='none'))\n",
    "\n",
    "        plt.show()\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "def start_training(model, train_dataloader, test_dataloader, optimizer, device, num_epochs=2):\n",
    "    # # Trainingsschleife\n",
    "    model.to(device)\n",
    "\n",
    "    # Define empty arrays to collect metrics\n",
    "    ap_values = []\n",
    "    ar_values = []\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # training for one epoch\n",
    "        train_one_epoch(model, optimizer, train_dataloader, device, epoch, print_freq=1, losses_out=losses)\n",
    "\n",
    "        # update the learning rate\n",
    "        # lr_scheduler.step()\n",
    "        \n",
    "        # evaluate on the test dataset        \n",
    "        evaluator = evaluate(model, test_dataloader, device=device)\n",
    "\n",
    "        # Extract the metrics from the evaluator\n",
    "        iou_thresholds = evaluator.coco_eval['bbox'].params.iouThrs\n",
    "        average_precisions = evaluator.coco_eval['bbox'].stats[:6]\n",
    "        average_recalls = evaluator.coco_eval['bbox'].stats[6:]\n",
    "\n",
    "        # Append the metrics to the arrays\n",
    "        ap_values.append(average_precisions)\n",
    "        ar_values.append(average_recalls)\n",
    "    \n",
    "    return ap_values, ar_values, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Definiere verschiedene Werte für die Hyperparameter\n",
    "normalize_options = [True, False]\n",
    "batch_size_options = [1, 2, 4, 8, 16]\n",
    "momentum_options = [0.85, 0.9, 0.95]\n",
    "nesterov_options = [True, False]\n",
    "\n",
    "# Erzeuge alle möglichen Kombinationen der Hyperparameter\n",
    "hyperparameter_combinations = list(itertools.product(normalize_options, batch_size_options, momentum_options, nesterov_options))\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_hyperparameters = None\n",
    "\n",
    "# Durchlaufe alle Kombinationen und trainiere das Modell mit jeder Kombination\n",
    "for normalize, batch_size, momentum, nesterov_options in hyperparameter_combinations:\n",
    "    # Setze die Hyperparameter auf die aktuellen Werte\n",
    "    NORMALIZE = normalize\n",
    "    BATCH_SIZE = batch_size\n",
    "    MOMENTUM = momentum\n",
    "    NESTEROV = nesterov_options\n",
    "    print(f\"Normalize: {normalize}, Batch Size: {batch_size}, Momentum: {momentum}, Nesterov: {nesterov_options}\")\n",
    "    # Erstelle das Modell und den Optimizer mit den aktuellen Hyperparametern\n",
    "    model, train_dataloader, test_dataloader, optimizer = setup_model(BATCH_SIZE, \n",
    "                                                       weights_backbone=VGG16_Weights.DEFAULT, \n",
    "                                                       weights=SSD300_VGG16_Weights.DEFAULT,                                                        \n",
    "                                                       lr=LEARNING_RATE,\n",
    "                                                       momentum=MOMENTUM,\n",
    "                                                       weight_decay=WEIGHT_DECAY,\n",
    "                                                       nesterov=NESTEROV,\n",
    "                                                       test_size=TEST_SIZE)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    ap_values, ar_values, losses = start_training(model, train_dataloader, test_dataloader, optimizer, device=device, num_epochs=NUM_EPOCHS)\n",
    "    plot_loss(losses)\n",
    "    plot_metrics(ap_values, ar_values)\n",
    "\n",
    "    # Bewerte die Leistung des Modells (z. B. Genauigkeit)\n",
    "    accuracy = np.max(ar_values)\n",
    "\n",
    "    # Speichere die besten Hyperparameter\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_hyperparameters = (normalize, batch_size, momentum)\n",
    "\n",
    "print(\"Beste Hyperparameter: \", best_hyperparameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_dataloader, test_dataloader, optimizer = setup_model(BATCH_SIZE, \n",
    "                                                       weights_backbone=VGG16_Weights.DEFAULT, \n",
    "                                                       weights=SSD300_VGG16_Weights.DEFAULT,                                                        \n",
    "                                                       lr=LEARNING_RATE,\n",
    "                                                       momentum=MOMENTUM,\n",
    "                                                       weight_decay=WEIGHT_DECAY,\n",
    "                                                       nesterov=NESTEROV,\n",
    "                                                       test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ap_values, ar_values, losses = start_training(model, train_dataloader, test_dataloader, optimizer, device=device, num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(losses)\n",
    "plot_metrics(ap_values, ar_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = next(iter(test_dataloader))\n",
    "visualize_prediction(samples[0], model, 0.5, [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
