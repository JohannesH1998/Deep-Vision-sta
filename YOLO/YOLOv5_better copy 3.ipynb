{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation von YOLOv5 mit Git und pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone \"https://github.com/ultralytics/yolov5.git\"\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kopieren von Bildern in den YOLOv5-Dataset-Ordner und Konvertieren von JSON-Daten in das YOLOv5-Format (txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split, Kopieren und Konvertieren erfolgreich.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Pfad zu den JSON-Daten und Bildern\n",
    "json_dir = \"../Datasets/Face Mask Detection Dataset/Medical mask/Medical mask/Medical mask/annotations\" \n",
    "image_dir = \"../Datasets/Face Mask Detection Dataset/Medical mask/Medical mask/Medical Mask/images\"  \n",
    "\n",
    "# Pfad zu den YOLOv5 Dataset-Ordnern\n",
    "labels_output_dir = \"yolov5/dataset/labels\"  \n",
    "image_output_dir = \"yolov5/dataset/images\"  \n",
    "\n",
    "# Bilder und Annotationen einlesen\n",
    "images = [os.path.join(image_dir, x) for x in os.listdir(image_dir)]\n",
    "annotations = [os.path.join(json_dir, x) for x in os.listdir(json_dir) if x.endswith(\".json\")]\n",
    "\n",
    "# Train-Test-Split\n",
    "if len(images) < 2 or len(annotations) < 2:\n",
    "    print(\"Nicht genügend Datenpunkte für den Split vorhanden.\")\n",
    "    exit()\n",
    "\n",
    "train_images, test_images, train_annotations, test_annotations = train_test_split(images, annotations, test_size=0.3, random_state=1)\n",
    "\n",
    "# Validierungs-Split\n",
    "val_images, test_images, val_annotations, test_annotations = train_test_split(test_images, test_annotations, test_size=0.5, random_state=1)\n",
    "\n",
    "# Funktion zum Kopieren von Dateien\n",
    "def copy_files_to_folder(file_list, destination_folder):\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "    \n",
    "    for file_path in file_list:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        destination_path = os.path.join(destination_folder, file_name)\n",
    "        shutil.copy(file_path, destination_path)\n",
    "\n",
    "# Funktion zur Konvertierung der Labels ins YOLOv5-Format\n",
    "def convert_labels_to_yolov5_format(json_path, image_path, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    class_mapping = {\n",
    "        \"face_no_mask\": 0,\n",
    "        \"face_with_mask\": 1,\n",
    "        \"mask_surgical\": 2,\n",
    "        \"hat\": 3,\n",
    "        \"eyeglasses\": 4,\n",
    "        \"face_other_covering\": 5,\n",
    "        \"face_with_mask_incorrect\": 6,\n",
    "        \"mask_colorful\": 7,\n",
    "        \"helmet\": 8,\n",
    "        \"sunglasses\": 9,\n",
    "        \"scarf_bandana\": 10,\n",
    "        \"hair_net\": 11,\n",
    "        \"goggles\": 12,\n",
    "        \"face_shield\": 13,\n",
    "        \"hijab_niqab\": 14,\n",
    "        \"turban\": 15,\n",
    "        \"balaclava_ski_mask\": 16,\n",
    "        \"gas_mask\": 17,\n",
    "        \"hood\": 18,\n",
    "        \"other\": 19\n",
    "    }\n",
    "\n",
    "    # Erstelle YOLOv5-Annotationen\n",
    "    with open(json_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    yolo_annotations = []\n",
    "    for bbox in json_data[\"Annotations\"]:\n",
    "        x_min, y_min, x_max, y_max = bbox[\"BoundingBox\"]\n",
    "        class_name = bbox[\"classname\"]\n",
    "\n",
    "        if class_name not in class_mapping:\n",
    "            raise ValueError(f\"Ungültige Klasse: {class_name}\")\n",
    "\n",
    "        class_index = class_mapping[class_name]\n",
    "\n",
    "        # Normalisierung der Koordinaten\n",
    "        x_center = (x_min + x_max) / (2 * image_width)\n",
    "        y_center = (y_min + y_max) / (2 * image_height)\n",
    "        width = (x_max - x_min) / image_width\n",
    "        height = (y_max - y_min) / image_height\n",
    "\n",
    "        yolo_annotation = f\"{class_index} {x_center} {y_center} {width} {height}\"\n",
    "        yolo_annotations.append(yolo_annotation)\n",
    "\n",
    "    image_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    output_filename = f\"{image_filename}.txt\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        for annotation in yolo_annotations:\n",
    "            f.write(annotation + '\\n')\n",
    "\n",
    "    # Erstelle classes.txt-Datei\n",
    "    classes_file_path = os.path.join(output_dir, \"classes.txt\")\n",
    "    with open(classes_file_path, 'w') as f:\n",
    "        for class_name, class_index in class_mapping.items():\n",
    "            f.write(f\"{class_index} {class_name}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Bilder in Trainings-, Validierungs- und Testordner kopieren\n",
    "train_image_output_dir = os.path.join(image_output_dir, \"train\")\n",
    "val_image_output_dir = os.path.join(image_output_dir, \"val\")\n",
    "test_image_output_dir = os.path.join(image_output_dir, \"test\")\n",
    "copy_files_to_folder(train_images, train_image_output_dir)\n",
    "copy_files_to_folder(val_images, val_image_output_dir)\n",
    "copy_files_to_folder(test_images, test_image_output_dir)\n",
    "\n",
    "# Labels in den entsprechenden Ordnern kopieren und ins YOLOv5-Format konvertieren\n",
    "train_labels_output_dir = os.path.join(labels_output_dir, \"train\")\n",
    "val_labels_output_dir = os.path.join(labels_output_dir, \"val\")\n",
    "test_labels_output_dir = os.path.join(labels_output_dir, \"test\")\n",
    "copy_files_to_folder(train_annotations, train_labels_output_dir)\n",
    "copy_files_to_folder(val_annotations, val_labels_output_dir)\n",
    "copy_files_to_folder(test_annotations, test_labels_output_dir)\n",
    "\n",
    "# Labels ins YOLOv5-Format konvertieren\n",
    "for json_path, image_path in zip(train_annotations, train_images):\n",
    "    convert_labels_to_yolov5_format(json_path, image_path, train_labels_output_dir)\n",
    "\n",
    "for json_path, image_path in zip(val_annotations, val_images):\n",
    "    convert_labels_to_yolov5_format(json_path, image_path, val_labels_output_dir)\n",
    "\n",
    "for json_path, image_path in zip(test_annotations, test_images):\n",
    "    convert_labels_to_yolov5_format(json_path, image_path, test_labels_output_dir)\n",
    "\n",
    "print(\"Split, Kopieren und Konvertieren erfolgreich.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSON-Dateien aus yolov5/dataset löschen\n",
    "def delete_json_files(folders):\n",
    "    for folder in folders:\n",
    "        if not os.path.exists(folder):\n",
    "            continue\n",
    "        \n",
    "        for filename in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            \n",
    "            if filename.endswith(\".json\"):\n",
    "                os.remove(file_path)\n",
    "\n",
    "folders = [\n",
    "    \"yolov5/dataset/labels/train\",\n",
    "    \"yolov5/dataset/labels/test\",\n",
    "    \"yolov5/dataset/labels/val\",\n",
    "]\n",
    "\n",
    "delete_json_files(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training von YOLOv5 mit WandB-Integration und Upload des Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda install pytorch=1.9.0 cudatoolkit=11.1 -c pytorch -c conda-forge  \n",
    "damit es läuft\n",
    "torchvision               0.10.0+cu111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.9.0 _CudaDeviceProperties(name='NVIDIA GeForce RTX 3080', major=8, minor=6, total_memory=10239MB, multi_processor_count=68)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Saniye\\Documents\\GitHub\\Deep-Vision-sta\\YOLO\\yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Saniye\\Documents\\GitHub\\Deep-Vision-sta\\YOLO\\yolov5\\train.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\Saniye\\anaconda3\\envs\\DEEP_VISION_KLONE4\\lib\\site-packages\\torch\\__init__.py\", line 124, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] Die Auslagerungsdatei ist zu klein, um diesen Vorgang durchzuführen. Error loading \"c:\\Users\\Saniye\\anaconda3\\envs\\DEEP_VISION_KLONE4\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops_gpu.dll\" or one of its dependencies.\n"
     ]
    }
   ],
   "source": [
    "!python train.py --data dataset/data.yaml --epochs 10 --weights '' --cfg yolov5s.yaml  --batch-size 6 --upload_dataset --bbox_interval 1 --img 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
