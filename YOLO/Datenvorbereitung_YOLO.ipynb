{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datenvorbereitung, in den YOLOv5 Datensatz Ordner + Konvertierung in das YOLO-Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import zipfile\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YOLOv5 und YOLOv4 Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone \"https://github.com/ultralytics/yolov5.git\"\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entzippen des YOLOv4 Ordners \n",
    "def zip_folder(folder_path):\n",
    "    with zipfile.ZipFile(folder_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                zipf.write(file_path, os.path.relpath(file_path, folder_path))\n",
    "yolo4 = \"yolov4.zip\"\n",
    "zip_folder(yolo4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov4\n",
    "%pip install -qr requirements.txt\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datensatz für Alle Klassen speichern\n",
    "Hierfür wird der Große Datensatz verwendet und alle 20 Klassen dieses Datensatzes werden verwendet. Diese werden für das YOLO Training in 70% Training, 15% Test und 15% Validierungsdatensatz getrennt.\n",
    "\n",
    "**Kopieren von Bildern in den YOLOv5-Dataset-Ordner und Konvertieren von JSON-Daten in das YOLO-Format (txt)**\n",
    " - erste Spalte: Klassenindizien\n",
    " - zweite bis fünfte Spalte: Koordinaten der Bounding Box (x, y, w, h), diese müssen normalisiert werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfad zu den JSON-Daten und Bildern\n",
    "json_dir = \"../Datasets/Face Mask Detection Dataset/Medical mask/Medical mask/Medical Mask/annotations\" \n",
    "image_dir = \"../Datasets/Face Mask Detection Dataset/Medical mask/Medical mask/Medical Mask/images\"  \n",
    "\n",
    "# Pfad zu den YOLOv5 Dataset-Ordnern\n",
    "labels_output_dir = \"yolov5/dataset/all_classes/labels\"  \n",
    "image_output_dir = \"yolov5/dataset/all_classes/images\"    \n",
    "\n",
    "#Klassen Mapping von allen Klassen\n",
    "class_mapping_all = {\n",
    "    \"face_no_mask\": 0,\n",
    "    \"face_with_mask\": 1,\n",
    "    \"mask_surgical\": 2,\n",
    "    \"hat\": 3,\n",
    "    \"eyeglasses\": 4,\n",
    "    \"face_other_covering\": 5,\n",
    "    \"face_with_mask_incorrect\": 6,\n",
    "    \"mask_colorful\": 7,\n",
    "    \"helmet\": 8,\n",
    "    \"sunglasses\": 9,\n",
    "    \"scarf_bandana\": 10,\n",
    "    \"hair_net\": 11,\n",
    "    \"goggles\": 12,\n",
    "    \"face_shield\": 13,\n",
    "    \"hijab_niqab\": 14,\n",
    "    \"turban\": 15,\n",
    "    \"balaclava_ski_mask\": 16,\n",
    "    \"gas_mask\": 17,\n",
    "    \"hood\": 18,\n",
    "    \"other\": 19\n",
    "}\n",
    "\n",
    "# Bilder und Annotationen einlesen\n",
    "images = [os.path.join(image_dir, x) for x in os.listdir(image_dir)]\n",
    "annotations = [os.path.join(json_dir, x) for x in os.listdir(json_dir) if x.endswith(\".json\")]\n",
    "\n",
    "# Train-Test-Split\n",
    "if len(images) < 2 or len(annotations) < 2:\n",
    "    print(\"Nicht genügend Datenpunkte für den Split vorhanden.\")\n",
    "    exit()\n",
    "\n",
    "# Train-Test-Split\n",
    "train_images, test_images, train_annotations, test_annotations = train_test_split(images, annotations, test_size=0.3, random_state=1)\n",
    "# Validierungs-Split\n",
    "val_images, test_images, val_annotations, test_annotations = train_test_split(test_images, test_annotations, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Kopieren von Dateien\n",
    "def copy_files_to_folder(file_list, destination_folder):\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "    \n",
    "    for file_path in file_list:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        destination_path = os.path.join(destination_folder, file_name)\n",
    "        shutil.copy(file_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Konvertierung der Labels ins YOLOv5-Format. Hier werden die Annotationen mit der Klassenindizierung versehen und \n",
    "# die Bounding Box Koordinaten normalisiert.\n",
    "def convert_labels_to_yolov5_format(json_path, image_path, output_dir, class_mapping):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Erstelle YOLOv5-Annotationen\n",
    "    with open(json_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    yolo_annotations = []\n",
    "    for bbox in json_data[\"Annotations\"]:\n",
    "        x_min, y_min, x_max, y_max = bbox[\"BoundingBox\"]\n",
    "        class_name = bbox[\"classname\"]\n",
    "\n",
    "        if class_name not in class_mapping:\n",
    "            raise ValueError(f\"Ungültige Klasse: {class_name}\")\n",
    "\n",
    "        # Klassenindizierung\n",
    "        class_index = class_mapping[class_name]\n",
    "\n",
    "        # Normalisierung der Koordinaten\n",
    "        x_center = (x_min + x_max) / (2 * image_width)\n",
    "        y_center = (y_min + y_max) / (2 * image_height)\n",
    "        width = (x_max - x_min) / image_width\n",
    "        height = (y_max - y_min) / image_height\n",
    "\n",
    "        yolo_annotation = f\"{class_index} {x_center} {y_center} {width} {height}\"\n",
    "        yolo_annotations.append(yolo_annotation)\n",
    "\n",
    "    image_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    output_filename = f\"{image_filename}.txt\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "    # Erstelle YOLOv5-Annotationen\n",
    "    with open(output_path, 'w') as f:\n",
    "        for annotation in yolo_annotations:\n",
    "            f.write(annotation + '\\n')\n",
    "\n",
    "    # Erstelle classes.txt-Datei, mit allen Klassen und deren Indizierung\n",
    "    classes_file_path = os.path.join(output_dir, \"classes.txt\")\n",
    "    with open(classes_file_path, 'w') as f:\n",
    "        for class_name, class_index in class_mapping.items():\n",
    "            f.write(f\"{class_index} {class_name}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All_Klasses Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(labels_output_dir, image_output_dir):\n",
    "    # Bilder in Trainings-, Validierungs- und Testordner kopieren\n",
    "    train_image_output_dir = os.path.join(image_output_dir, \"train\")\n",
    "    val_image_output_dir = os.path.join(image_output_dir, \"val\")\n",
    "    test_image_output_dir = os.path.join(image_output_dir, \"test\")\n",
    "    copy_files_to_folder(train_images, train_image_output_dir)\n",
    "    copy_files_to_folder(val_images, val_image_output_dir)\n",
    "    copy_files_to_folder(test_images, test_image_output_dir)\n",
    "\n",
    "    # Labels in den entsprechenden Ordnern kopieren und ins YOLOv5-Format konvertieren\n",
    "    train_labels_output_dir = os.path.join(labels_output_dir, \"train\")\n",
    "    val_labels_output_dir = os.path.join(labels_output_dir, \"val\")\n",
    "    test_labels_output_dir = os.path.join(labels_output_dir, \"test\")\n",
    "    copy_files_to_folder(train_annotations, train_labels_output_dir)\n",
    "    copy_files_to_folder(val_annotations, val_labels_output_dir)\n",
    "    copy_files_to_folder(test_annotations, test_labels_output_dir)\n",
    "\n",
    "    return train_labels_output_dir, val_labels_output_dir, test_labels_output_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json(train_labels_output_dir, val_labels_output_dir, test_labels_output_dir, class_mapping):\n",
    "    # Labels ins YOLOv5-Format konvertieren\n",
    "    for json_path, image_path in zip(train_annotations, train_images):\n",
    "        convert_labels_to_yolov5_format(json_path, image_path, train_labels_output_dir, class_mapping)\n",
    "\n",
    "    for json_path, image_path in zip(val_annotations, val_images):\n",
    "        convert_labels_to_yolov5_format(json_path, image_path, val_labels_output_dir, class_mapping)\n",
    "\n",
    "    for json_path, image_path in zip(test_annotations, test_images):\n",
    "        convert_labels_to_yolov5_format(json_path, image_path, test_labels_output_dir, class_mapping)\n",
    "\n",
    "    print(\"Kopieren und Konvertieren erfolgreich.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_folder(source, destination):\n",
    "    if not os.path.exists(destination):  # Überprüfen, ob der Zielordner bereits existiert\n",
    "        shutil.copytree(source, destination)\n",
    "        print(f\"Ordner '{source}' wurde erfolgreich nach '{destination}' kopiert.\")\n",
    "    else:\n",
    "        print(f\"Zielordner '{destination}' existiert bereits. Kopiervorgang abgebrochen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz wird in die YOLOv5-Ordner kopiert und gesplittet. Hier noch keine Konvertierung der Labels.\n",
    "train_labels_output_dir, val_labels_output_dir, test_labels_output_dir = split_dataset(labels_output_dir, image_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordner 'yolov5/dataset/all_classes' wurde erfolgreich nach 'yolov5/dataset/face_classes' kopiert.\n",
      "Ordner 'yolov5/dataset/all_classes' wurde erfolgreich nach 'yolov5/dataset/one_person' kopiert.\n"
     ]
    }
   ],
   "source": [
    "# Kopieren der Datensätze für zwei weitere YOLOv5-Trainings (Diese werden später benötigt und müssen angepasst werden.)\n",
    "all_classes = \"yolov5/dataset/all_classes\"\n",
    "faces_classes = \"yolov5/dataset/face_classes\"\n",
    "one_person = \"yolov5/dataset/one_person\"\n",
    "copy_folder(all_classes, faces_classes)\n",
    "copy_folder(all_classes, one_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kopieren und Konvertieren erfolgreich.\n"
     ]
    }
   ],
   "source": [
    "# Konvertieren der JSON-Labels ins YOLOv5-Format\n",
    "convert_json(train_labels_output_dir, val_labels_output_dir, test_labels_output_dir, class_mapping_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSON-Dateien aus yolov5/dataset löschen\n",
    "def delete_json_files(folders):\n",
    "    for folder in folders:\n",
    "        if not os.path.exists(folder):\n",
    "            continue\n",
    "        \n",
    "        for filename in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            \n",
    "            if filename.endswith(\".json\"):\n",
    "                os.remove(file_path)\n",
    "\n",
    "folders = [\n",
    "    \"yolov5/dataset/all_classes/labels/train\",\n",
    "    \"yolov5/dataset/all_classes/labels/test\",\n",
    "    \"yolov5/dataset/all_classes/labels/val\",\n",
    "]\n",
    "\n",
    "delete_json_files(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Face_Classes für Training erstellen\n",
    "Hier wird derselbe Datensatz verwendet wie oben bei der Datenvorbereitung, der den großen Datensatz mit den JSON-Dateien enthält. In diesem Fall liegt der Fokus auf dem Anwendungsfall der Face_Classes. Das bedeutet, dass wir mit insgesamt 4 Klassen trainieren werden. Vor der Konvertierung in das YOLO-Format müssen jedoch alle anderen Klassen in der Annotationsdatei identifiziert und entfernt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identifizierung und Löschen von JSON-Zeilen, die nicht den Face_Classes entsprechen, die für das Training verwendet werden sollen.\n",
    "def filter_json_files(folder_path, class_mapping_faces):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            filtered_annotations = [annotation for annotation in data[\"Annotations\"] if annotation[\"classname\"] in class_mapping_faces]\n",
    "            data[\"Annotations\"] = filtered_annotations\n",
    "\n",
    "            with open(file_path, 'w') as file:\n",
    "                json.dump(data, file)\n",
    "\n",
    "folder_path1 = \"yolov5/dataset/face_classes/labels/test\"\n",
    "folder_path2 = \"yolov5/dataset/face_classes/labels/val\"\n",
    "folder_path3 = \"yolov5/dataset/face_classes/labels/train\"\n",
    "\n",
    "class_mapping_faces = [\n",
    "    \"face_no_mask\",\n",
    "    \"face_with_mask\",\n",
    "    \"face_other_covering\",\n",
    "    \"face_with_mask_incorrect\"\n",
    "]\n",
    "\n",
    "# Löschen der nicht benötigten Klassen\n",
    "filter_json_files(folder_path1, class_mapping_faces)\n",
    "filter_json_files(folder_path2, class_mapping_faces)\n",
    "filter_json_files(folder_path3, class_mapping_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faces-JSON-Dateien in YOLOv5-Format konvertieren dabei werden die Klassen neu nummeriert\n",
    "def convert_json_to_yolo(json_path, image_path, output_dir, class_mapping):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Öffne JSON-Datei\n",
    "    with open(json_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    yolo_annotations = []\n",
    "    for bbox in json_data[\"Annotations\"]:\n",
    "        x_min, y_min, x_max, y_max = bbox[\"BoundingBox\"]\n",
    "        class_name = bbox[\"classname\"]\n",
    "\n",
    "        if class_name not in class_mapping:\n",
    "            raise ValueError(f\"Ungültige Klasse: {class_name}\")\n",
    "\n",
    "        # Klassenindizierung\n",
    "        class_index = class_mapping[class_name]\n",
    "\n",
    "        # Normalisierung der Koordinaten\n",
    "        x_center = (x_min + x_max) / (2 * image_width)\n",
    "        y_center = (y_min + y_max) / (2 * image_height)\n",
    "        width = (x_max - x_min) / image_width\n",
    "        height = (y_max - y_min) / image_height\n",
    "\n",
    "        yolo_annotation = f\"{class_index} {x_center} {y_center} {width} {height}\"\n",
    "        yolo_annotations.append(yolo_annotation)\n",
    "\n",
    "    image_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    output_filename = f\"{image_filename}.txt\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        for annotation in yolo_annotations:\n",
    "            f.write(annotation + '\\n')\n",
    "\n",
    "def get_image_filename_without_extension(filename):\n",
    "    return os.path.splitext(filename)[0]\n",
    "\n",
    "\n",
    "def convert_json_files_to_yolo(json_directory, image_directory, output_directory, class_mapping):\n",
    "    for filename in os.listdir(json_directory):\n",
    "        if filename.endswith(\".json\"):\n",
    "            json_path = json_directory + \"/\"+ filename\n",
    "            image_filename_without_extension = get_image_filename_without_extension(filename)\n",
    "\n",
    "            # Check for JPEG image\n",
    "            image_path =  image_directory + \"/\"+ image_filename_without_extension\n",
    "            if not os.path.exists(image_path):\n",
    "                # Check for JPG image\n",
    "                image_path = image_directory + \"/\"+ image_filename_without_extension\n",
    "                if not os.path.exists(image_path):\n",
    "                    # Check for PNG image\n",
    "                    image_path = image_directory + \"/\"+ image_filename_without_extension\n",
    "                    if not os.path.exists(image_path):\n",
    "                        print(f\"Image file not found for JSON: {image_path}\")\n",
    "                        continue  # Skip this JSON file if no corresponding image is found\n",
    "            convert_json_to_yolo(json_path, image_path, output_directory, class_mapping)\n",
    "\n",
    "# classes.txt enthält die Klassenindizierung und die Klassennamen\n",
    "def write_classes_to_file(class_mapping, json_directory):\n",
    "    classes_file_path = os.path.join(json_directory, \"classes.txt\")\n",
    "    with open(classes_file_path, 'w') as f:\n",
    "        for class_name, class_index in class_mapping.items():\n",
    "            f.write(f\"{class_index} {class_name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_directory1 = \"yolov5/dataset/face_classes/labels/test/\"\n",
    "image_directory1 = \"yolov5/dataset/face_classes/images/test\"\n",
    "json_directory2 = \"yolov5/dataset/face_classes/labels/val/\"\n",
    "image_directory2 = \"yolov5/dataset/face_classes/images/val\"\n",
    "json_directory3 = \"yolov5/dataset/face_classes/labels/train/\"\n",
    "image_directory3 = \"yolov5/dataset/face_classes/images/train\"\n",
    "\n",
    "# Klassenmapping\n",
    "class_mapping_faces = {\n",
    "    \"face_no_mask\": 0,\n",
    "    \"face_with_mask\": 1,\n",
    "    \"face_other_covering\": 2,\n",
    "    \"face_with_mask_incorrect\": 3,\n",
    "}\n",
    "\n",
    "# Konvertieren der JSON-Dateien ins YOLOv5-Format\n",
    "convert_json_files_to_yolo(json_directory1, image_directory1, json_directory1, class_mapping_faces)\n",
    "convert_json_files_to_yolo(json_directory2, image_directory2, json_directory2, class_mapping_faces)\n",
    "convert_json_files_to_yolo(json_directory3, image_directory3, json_directory3, class_mapping_faces)\n",
    "write_classes_to_file(class_mapping_faces, json_directory1)\n",
    "write_classes_to_file(class_mapping_faces, json_directory2)\n",
    "write_classes_to_file(class_mapping_faces, json_directory3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\n",
    "    json_directory1,\n",
    "    json_directory2,\n",
    "    json_directory3,\n",
    "]\n",
    "# Löschen der JSON-Dateien\n",
    "delete_json_files(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Einzel Personen Datensatz\n",
    "In diesem Datensatz wird ebenfalls der große Datensatz mit den JSON-Annotationen verarbeitet. Hier liegt der Fokus ausschließlich auf einzelnen Gesichtern. Das bedeutet, dass Bilder mit mehreren erkannten Gesichtern in diesem Datensatz entfernt werden. Dazu werden nur die 4 Face_Classes berücksichtigt, und es ist bekannt, dass in einer TXT-Datei mehrere Face_Classes darauf hinweisen, dass mehrere Personen erkannt wurden. Solche TXT-Dateien und die dazugehörigen Bilder werden gelöscht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_folder_path1 = \"yolov5/dataset/one_person/labels/test\"\n",
    "label_folder_path2 = \"yolov5/dataset/one_person/labels/val\"\n",
    "label_folder_path3 = \"yolov5/dataset/one_person/labels/train\"\n",
    "\n",
    "filter_json_files(label_folder_path1, class_mapping_faces)\n",
    "filter_json_files(label_folder_path2, class_mapping_faces)\n",
    "filter_json_files(label_folder_path3, class_mapping_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überprüfung, ob die Face-Class mehr als einmal in einer JSON-Datei vorkommt\n",
    "def check_classname_frequency(data):\n",
    "    classname_count = {}\n",
    "    for annotation in data['Annotations']:\n",
    "        classname = annotation['classname']\n",
    "        if classname in classname_count:\n",
    "            classname_count[classname] += 1\n",
    "        else:\n",
    "            classname_count[classname] = 1\n",
    "\n",
    "    for classname, count in classname_count.items():\n",
    "        if classname in class_mapping_faces and count > 1:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Löschen der JSON-Dateien, die die Face-Class mehr als einmal enthalten\n",
    "def filterjson_files(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            if check_classname_frequency(data):\n",
    "                os.remove(file_path)\n",
    "\n",
    "# Löschen der JSON-Dateien mit mehr Klassen\n",
    "filterjson_files(label_folder_path1)\n",
    "filterjson_files(label_folder_path2)\n",
    "filterjson_files(label_folder_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überprüfung, ob die JSON-Dateien und Bilder übereinstimmen, nach dem Löschen der JSON-Dateien\n",
    "def check_json_images(json_folder, image_folder):\n",
    "    # Liste aller JSON-Dateien\n",
    "    json_files = [file.split(\".jpg.json\")[0].split(\".jpeg.json\")[0].split(\".png.json\")[0] for file in os.listdir(json_folder) if file.endswith((\".jpg.json\", \".jpeg.json\", \".png.json\"))]\n",
    "\n",
    "    # Durchsuche Bilderordner nach Dateien ohne entsprechende JSON-Datei\n",
    "    for file in os.listdir(image_folder):\n",
    "        if file.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            image_name = file.split(\".\")[0]\n",
    "            if image_name not in json_files:\n",
    "                # Lösche das Bild, da keine JSON-Datei vorhanden ist\n",
    "                image_path = os.path.join(image_folder, file)\n",
    "                os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder1 = \"yolov5/dataset/one_person/images/test\"\n",
    "image_folder2 = \"yolov5/dataset/one_person/images/val\"\n",
    "image_folder3 = \"yolov5/dataset/one_person/images/train\"\n",
    "\n",
    "label_folder_path1 = \"yolov5/dataset/one_person/labels/test\"\n",
    "label_folder_path2 = \"yolov5/dataset/one_person/labels/val\"\n",
    "label_folder_path3 = \"yolov5/dataset/one_person/labels/train\"\n",
    "\n",
    "# Checke, ob alle Bilder eine JSON-Datei haben\n",
    "check_json_images(label_folder_path1, image_folder1)\n",
    "check_json_images(label_folder_path2, image_folder2)\n",
    "check_json_images(label_folder_path3, image_folder3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konvertieren der JSON-Dateien ins YOLOv5-Format und classes.txt-Datei erstellen\n",
    "convert_json_files_to_yolo(label_folder_path1, image_folder1, label_folder_path1, class_mapping_faces)\n",
    "convert_json_files_to_yolo(label_folder_path2, image_folder2, label_folder_path2, class_mapping_faces)\n",
    "convert_json_files_to_yolo(label_folder_path3, image_folder3, label_folder_path3, class_mapping_faces)\n",
    "write_classes_to_file(class_mapping_faces, label_folder_path1)\n",
    "write_classes_to_file(class_mapping_faces, label_folder_path2)\n",
    "write_classes_to_file(class_mapping_faces, label_folder_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\n",
    "    label_folder_path1,\n",
    "    label_folder_path2,\n",
    "    label_folder_path3,\n",
    "]\n",
    "\n",
    "# Löschen der JSON-Dateien\n",
    "delete_json_files(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überprüfung, ob die TXT-Dateien und Bilder übereinstimmen mit außnahme der classes.txt-Datei\n",
    "def check_txt_images(txt_folder, image_folder):\n",
    "    # Überprüfe, ob die Datei \"classes.txt\" vorhanden ist\n",
    "    classes_txt_path = os.path.join(txt_folder, \"classes.txt\")\n",
    "    if not os.path.exists(classes_txt_path):\n",
    "        return\n",
    "    \n",
    "    # Liste aller TXT-Dateien\n",
    "    txt_files = [file for file in os.listdir(txt_folder) if file.endswith(\".txt\")]\n",
    "\n",
    "    # Durchsuche TXT-Ordner nach Dateien ohne entsprechendes Bild, außer \"classes.txt\"\n",
    "    for txt_file in txt_files:\n",
    "        if txt_file != \"classes.txt\":\n",
    "            txt_name = txt_file.split(\".\")[0]\n",
    "            image_path = os.path.join(image_folder, f\"{txt_name}.jpg\")\n",
    "            if not (os.path.exists(image_path) or os.path.exists(image_path[:-4] + \".jpeg\") or os.path.exists(image_path[:-4] + \".png\")):\n",
    "                # Drucke den Namen der fehlenden Bild-Datei\n",
    "                print(f\"Fehlendes Bild für TXT-Datei: {txt_file}\")\n",
    "\n",
    "    # Durchsuche Bilderordner nach Bildern ohne entsprechende TXT-Datei\n",
    "    for image_file in os.listdir(image_folder):\n",
    "        if image_file.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            image_name = image_file.split(\".\")[0]\n",
    "            txt_path = os.path.join(txt_folder, f\"{image_name}.txt\")\n",
    "            if not os.path.exists(txt_path) and image_name != \"classes\":\n",
    "                # Drucke den Namen der fehlenden TXT-Datei\n",
    "                print(f\"Fehlende TXT-Datei für Bild: {image_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überprüfung, ob die TXT-Dateien und Bilder übereinstimmen für alle drei Datensätze\n",
    "check_txt_images(\"yolov5/dataset/all_classes/labels/train\", \"yolov5/dataset/all_classes/images/train\")\n",
    "check_txt_images(\"yolov5/dataset/all_classes/labels/test\", \"yolov5/dataset/all_classes/images/test\")\n",
    "check_txt_images(\"yolov5/dataset/all_classes/labels/val\", \"yolov5/dataset/all_classes/images/val\")\n",
    "check_txt_images(\"yolov5/dataset/face_classes/labels/train\", \"yolov5/dataset/face_classes/images/train\")\n",
    "check_txt_images(\"yolov5/dataset/face_classes/labels/test\", \"yolov5/dataset/face_classes/images/test\")\n",
    "check_txt_images(\"yolov5/dataset/face_classes/labels/val\", \"yolov5/dataset/face_classes/images/val\")\n",
    "check_txt_images(\"yolov5/dataset/one_person/labels/train\", \"yolov5/dataset/one_person/images/train\")\n",
    "check_txt_images(\"yolov5/dataset/one_person/labels/test\", \"yolov5/dataset/one_person/images/test\")\n",
    "check_txt_images(\"yolov5/dataset/one_person/labels/val\", \"yolov5/dataset/one_person/images/val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dark Datensatz\n",
    "Der Dunkle Datensatz wurde durch Augmentation verdunkelt, da wir keinen bereits dunklen Datensatz in Kaggle finden konnten. Ziel ist es, ein Modell zu trainieren, das auch im Dunkeln Masken erkennen kann. In diesem Datensatz werden ausschließlich die 4 Face_Classes betrachtet. Es ist wichtig zu beachten, dass die Annotationen für diesen Datensatz als XML-Dateien vorliegen und in das YOLO-Format konvertiert werden müssen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Konvertierung der XML-Datei ins YOLOv5-Format\n",
    "def convert_xml_to_yolo(xml_path, image_directory, output_dir, class_mapping):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Öffne XML-Datei\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Holen Sie sich den Dateinamen des Bildes (ohne Erweiterung)\n",
    "    image_filename_without_extension = os.path.splitext(root.find('filename').text)[0]\n",
    "\n",
    "    # Bildpfad\n",
    "    image_path = os.path.join(image_directory, f\"{image_filename_without_extension}.png\")\n",
    "\n",
    "    # Überprüfen Sie, ob das Bild vorhanden ist\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image file not found: {image_path}\")\n",
    "        return\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    yolo_annotations = []\n",
    "    for obj in root.findall('object'):\n",
    "        class_name = obj.find('name').text\n",
    "\n",
    "        if class_name not in class_mapping:\n",
    "            raise ValueError(f\"Ungültige Klasse: {class_name}\")\n",
    "\n",
    "        # Klassenindizierung\n",
    "        class_index = class_mapping[class_name]\n",
    "\n",
    "        # Bounding Box Koordinaten\n",
    "        bbox = obj.find('bndbox')\n",
    "        x_min = float(bbox.find('xmin').text)\n",
    "        y_min = float(bbox.find('ymin').text)\n",
    "        x_max = float(bbox.find('xmax').text)\n",
    "        y_max = float(bbox.find('ymax').text)\n",
    "\n",
    "        # Normalisierung der Koordinaten\n",
    "        x_center = (x_min + x_max) / (2 * image_width)\n",
    "        y_center = (y_min + y_max) / (2 * image_height)\n",
    "        width = (x_max - x_min) / image_width\n",
    "        height = (y_max - y_min) / image_height\n",
    "\n",
    "        yolo_annotation = f\"{class_index} {x_center} {y_center} {width} {height}\"\n",
    "        yolo_annotations.append(yolo_annotation)\n",
    "\n",
    "    output_filename = f\"{image_filename_without_extension}.txt\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        for annotation in yolo_annotations:\n",
    "            f.write(annotation + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_directory = \"../Datasets/Kaggle Face Mask Detection Full/annotations\"\n",
    "image_directory = \"../Datasets/Kaggle Face Mask Detection Full/dark/images\"\n",
    "output_directory = \"yolov5/dataset/dark/labels\"\n",
    "\n",
    "# Klassenmapping\n",
    "class_mapping_dark = {\n",
    "    \"without_mask\": 0,\n",
    "    \"with_mask\": 1,\n",
    "    \"mask_weared_incorrect\": 2,\n",
    "}\n",
    "\n",
    "def convert_xml_files_to_yolo(xml_directory, image_directory, output_directory, class_mapping):\n",
    "    for filename in os.listdir(xml_directory):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            xml_path = os.path.join(xml_directory, filename)\n",
    "            convert_xml_to_yolo(xml_path, image_directory, output_directory, class_mapping)\n",
    "\n",
    "# Rufen Sie die Funktion auf, um die XML-Dateien in das YOLOv5-Format umzuwandeln\n",
    "convert_xml_files_to_yolo(xml_directory, image_directory, output_directory, class_mapping_dark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfad zu den YOLOv5 Dataset-Ordnern\n",
    "labels_output_dir = \"yolov5/dataset/dark/labels\"  \n",
    "image_output_dir = \"yolov5/dataset/dark/images\"  \n",
    "\n",
    "# Bilder und Annotationen einlesen\n",
    "images = [os.path.join(image_directory, x) for x in os.listdir(image_directory)]\n",
    "annotations = [os.path.join(output_directory, x) for x in os.listdir(output_directory) if x.endswith(\".txt\")]\n",
    "\n",
    "# Train-Test-Split\n",
    "if len(images) < 2 or len(annotations) < 2:\n",
    "    print(\"Nicht genügend Datenpunkte für den Split vorhanden.\")\n",
    "    exit()\n",
    "\n",
    "# Train-Test-Split\n",
    "train_images, test_images, train_annotations, test_annotations = train_test_split(images, annotations, test_size=0.3, random_state=1)\n",
    "# Validierungs-Split\n",
    "val_images, test_images, val_annotations, test_annotations = train_test_split(test_images, test_annotations, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitten der Bilder und Annotationen\n",
    "train_labels_output_dir, val_labels_output_dir, test_labels_output_dir = split_dataset(labels_output_dir, image_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# löschen der überschüssigen txt-Dateien im labels Ordner die nicht benötigt werden\n",
    "def delete_files_in_folder(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Löschen der Datei {file_path}: {e}\")\n",
    "\n",
    "# Ordner mit den überschüssigen txt-Dateien löschen (dataset/dark/labels)\n",
    "delete_files_in_folder(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_test = \"yolov5/dataset/dark/labels/test\"\n",
    "label_val = \"yolov5/dataset/dark/labels/val\"\n",
    "label_train = \"yolov5/dataset/dark/labels/train\"\n",
    "\n",
    "# Klassen mit Klassenindizierung in die classes.txt schreiben\n",
    "write_classes_to_file(class_mapping_dark, label_test)\n",
    "write_classes_to_file(class_mapping_dark, label_val)\n",
    "write_classes_to_file(class_mapping_dark, label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YAML-Datei für alle Datensätze erstellen\n",
    "Die YAML-Datei ist eine Konfigurationsdatei für das Training des YOLO-Modells. Diese ist wie folgt aufgebaut:\n",
    "- `train`: Pfad zum Verzeichnis, das die Trainingsbilder enthält.\n",
    "- `val`: Pfad zum Verzeichnis mit den Validierungsbildern.\n",
    "- `test`: Pfad zum Verzeichnis mit den Testbildern.\n",
    "- `nc`: Anzahl der Klassen im Datensatz.\n",
    "- `names`: Eine Liste der Klassennamen. \n",
    "- `patience`: Anzahl der Epochen, die gewartet werden, wenn die Leistung des Modells nicht besser wird, bevor das Training beendet wird. Hierbei kann bei Overfitting das Training automatisch abgebrochen werden.\n",
    "- `delta`: Schwellenwert, um zu bestimmen, ob die Leistung des Modells sich verbessert hat. Wenn die Verbesserung kleiner als dieser Schwellenwert ist, wird das Training gestoppt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_yaml_file(data_path, train_path, val_path, test_path, class_names_file):\n",
    "    with open(class_names_file, 'r') as f:\n",
    "        class_names = [line.strip().split(' ', 1)[1] for line in f.readlines()]\n",
    "\n",
    "    data_yaml = f\"train: {train_path}\\n\" \\\n",
    "                f\"val: {val_path}\\n\" \\\n",
    "                f\"test: {test_path}\\n\" \\\n",
    "                f\"nc: {len(class_names)}\\n\" \\\n",
    "                f\"names: {class_names}\\n\" \\\n",
    "                f\"patience: 5  # Anzahl der Epochen, die gewartet werden, wenn die Leistung nicht besser wird\\n\" \\\n",
    "                f\"delta: 0.0001  # Schwellenwert, um zu bestimmen, ob die Leistung sich verbessert hat\\n\" \n",
    "    \n",
    "    with open(data_path, 'w') as file:\n",
    "        file.write(data_yaml)\n",
    "    \n",
    "    print(f\"Die data.yaml-Datei wurde erfolgreich erstellt: {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die data.yaml-Datei wurde erfolgreich erstellt: yolov5/dataset/all_classes/data.yaml\n"
     ]
    }
   ],
   "source": [
    "#YAML-Datei für all_classes\n",
    "create_data_yaml_file(\"yolov5/dataset/all_classes/data.yaml\", \n",
    "                      \"../yolov5/dataset/all_classes/images/train/\", \n",
    "                      \"../yolov5/dataset/all_classes/images/val/\",\n",
    "                      \"../yolov5/dataset/all_classes/images/test/\",\n",
    "                      \"yolov5/dataset/all_classes/labels/train/classes.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die data.yaml-Datei wurde erfolgreich erstellt: yolov5/dataset/face_classes/data.yaml\n"
     ]
    }
   ],
   "source": [
    "#YAML-Datei für face_classes\n",
    "create_data_yaml_file(  \"yolov5/dataset/face_classes/data.yaml\",\n",
    "                        \"../yolov5/dataset/face_classes/images/train/\",\n",
    "                        \"../yolov5/dataset/face_classes/images/val/\",\n",
    "                        \"../yolov5/dataset/face_classes/images/test/\",\n",
    "                        \"yolov5/dataset/face_classes/labels/train/classes.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die data.yaml-Datei wurde erfolgreich erstellt: yolov5/dataset/one_person/data.yaml\n"
     ]
    }
   ],
   "source": [
    "#YAML-Datei für one_person\n",
    "create_data_yaml_file(  \"yolov5/dataset/one_person/data.yaml\",\n",
    "                        \"../yolov5/dataset/one_person/images/train/\",\n",
    "                        \"../yolov5/dataset/one_person/images/val/\",\n",
    "                        \"../yolov5/dataset/one_person/images/test/\",\n",
    "                        \"yolov5/dataset/one_person/labels/train/classes.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die data.yaml-Datei wurde erfolgreich erstellt: yolov5/dataset/dark/data.yaml\n"
     ]
    }
   ],
   "source": [
    "#YAML-Datei für dark\n",
    "create_data_yaml_file(  \"yolov5/dataset/dark/data.yaml\",\n",
    "                        \"../yolov5/dataset/dark/images/train/\",\n",
    "                        \"../yolov5/dataset/dark/images/val/\",\n",
    "                        \"../yolov5/dataset/dark/images/test/\",\n",
    "                        \"yolov5/dataset/dark/labels/train/classes.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
